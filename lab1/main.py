import pandas as pd
import os
from pathlib import Path
from typing import Optional, Dict, Any
import time
from tqdm import tqdm
import torch
import pandas as pd
import numpy as np
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import re
import os
import gc
import json
from pathlib import Path
from typing import Optional, Dict, Any
import time
from tqdm import tqdm
from typing import Literal, Optional, Tuple, List



def load_model_tokenizer(
    model_name = "Qwen/Qwen2.5-14B-Instruct",
):
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    if tokenizer.pad_token is None or not tokenizer.pad_token:
        tokenizer.pad_token = tokenizer.eos_token
    quantization_config = BitsAndBytesConfig(
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.float16,
        bnb_4bit_use_double_quant=True,
        load_in_4bit=True,
    )
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=quantization_config,
        device_map="auto",
        trust_remote_code=True
    )
    print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    return model, tokenizer

model_14b, tokenizer_14b = load_model_tokenizer("Qwen/Qwen2.5-14B-Instruct")


PROMPTS = {
    "physics": """
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–∏–∑–∏–∫–µ. –†–µ—à–∏ –∑–∞–¥–∞—á—É –ø–æ —Ñ–∏–∑–∏–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥ –ø–æ—à–∞–≥–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (Chain-of-Thought):

1. –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–æ–π —Ä–∞–∑–¥–µ–ª —Ñ–∏–∑–∏–∫–∏ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω (–º–µ—Ö–∞–Ω–∏–∫–∞, —ç–ª–µ–∫—Ç—Ä–æ–º–∞–≥–Ω–µ—Ç–∏–∑–º, —Ç–µ—Ä–º–æ–¥–∏–Ω–∞–º–∏–∫–∞, –æ–ø—Ç–∏–∫–∞ –∏ —Ç.–¥.)
2. –í—ã–ø–∏—à–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã –∏ —á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏
3. –í—Å–ø–æ–º–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–æ—Ä–º—É–ª—ã –∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã
4. –ü—Ä–∏–º–µ–Ω–∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –ø–æ —à–∞–≥–∞–º, –ø–æ–∫–∞–∑—ã–≤–∞—è –≤—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
5. –ü—Ä–æ–≤–µ—Ä—å –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
6. –û—Ü–µ–Ω–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º

–í–Ω–∏–º–∞–Ω–∏–µ: –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–∞–π –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (0, 1, 2 –∏–ª–∏ 3). –ù–µ –ø–∏—à–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.
""",

    "chemistry": """
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-—Ö–∏–º–∏–∫. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ —Ö–∏–º–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥–∏–∫—É –ø–æ—à–∞–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:

1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø —Ö–∏–º–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: —Å—Ç–µ—Ö–∏–æ–º–µ—Ç—Ä–∏—è, —Ö–∏–º–∏—á–µ—Å–∫–∞—è —Å–≤—è–∑—å, —Ç–µ—Ä–º–æ—Ö–∏–º–∏—è, –∫–∏–Ω–µ—Ç–∏–∫–∞, —Ä–∞–≤–Ω–æ–≤–µ—Å–∏–µ –∏ —Ç.–¥.
2. –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–∏–º–∏—á–µ—Å–∫–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ - –ø—Ä–æ–≤–µ—Ä—å –µ–≥–æ –±–∞–ª–∞–Ω—Å
3. –û–ø—Ä–µ–¥–µ–ª–∏ –º–æ–ª—è—Ä–Ω—ã–µ –º–∞—Å—Å—ã –∏ —Å—Ç–µ—Ö–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
4. –î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ —Å–≤–æ–π—Å—Ç–≤–∞—Ö - –≤—Å–ø–æ–º–Ω–∏ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏
5. –î–ª—è –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–æ–π —Ö–∏–º–∏–∏ - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã
6. –ü—Ä–æ–≤–µ—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–π –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0-3). –ë–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.
""",

    "biology": """
–¢—ã –±–∏–æ–ª–æ–≥ —Å –≥–ª—É–±–æ–∫–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏. –ò—Å–ø–æ–ª—å–∑—É–π –º–µ—Ç–æ–¥ –ª–æ–≥–∏—á–µ—Å–∫–æ–π —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ –±–∏–æ–ª–æ–≥–∏–∏:

1. –û–ø—Ä–µ–¥–µ–ª–∏ –æ–±–ª–∞—Å—Ç—å –±–∏–æ–ª–æ–≥–∏–∏: –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–∞—è, –∫–ª–µ—Ç–æ—á–Ω–∞—è, –≥–µ–Ω–µ—Ç–∏–∫–∞, —ç–≤–æ–ª—é—Ü–∏—è, —ç–∫–æ–ª–æ–≥–∏—è, –∞–Ω–∞—Ç–æ–º–∏—è
2. –î–ª—è –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ - –≤—Å–ø–æ–º–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –î–ù–ö/–†–ù–ö, –±–µ–ª–∫–∏, —Ñ–µ—Ä–º–µ–Ω—Ç—ã
3. –î–ª—è –∫–ª–µ—Ç–æ—á–Ω–æ–π –±–∏–æ–ª–æ–≥–∏–∏ - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏ –æ—Ä–≥–∞–Ω–µ–ª–ª—ã –∏ –∏—Ö —Ñ—É–Ω–∫—Ü–∏–∏
4. –î–ª—è –≥–µ–Ω–µ—Ç–∏–∫–∏ - –ø—Ä–∏–º–µ–Ω–∏ –∑–∞–∫–æ–Ω—ã –ú–µ–Ω–¥–µ–ª—è, –≤—Å–ø–æ–º–Ω–∏ –æ –î–ù–ö, –†–ù–ö, –º—É—Ç–∞—Ü–∏—è—Ö
5. –î–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–±–æ—Ä, –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
6. –ü—Ä–æ–≤–µ—Ä—å –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –ª–æ–≥–∏–∫—É –æ—Ç–≤–µ—Ç–∞

–í –∫–æ–Ω—Ü–µ –¥–∞–π –¢–û–õ–¨–ö–û —Ü–∏—Ñ—Ä—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
""",

    "math": """
–¢—ã –º–∞—Ç–µ–º–∞—Ç–∏–∫. –†–µ—à–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É, –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç—Ä–æ–≥–æ–µ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ:

1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∑–∞–¥–∞—á–∏: –∞–ª–≥–µ–±—Ä–∞, –≥–µ–æ–º–µ—Ç—Ä–∏—è, —Ç—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—è, –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑, —Ç–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
2. –í—ã–ø–∏—à–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ
3. –í—Å–ø–æ–º–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–µ–æ—Ä–µ–º—ã, —Ñ–æ—Ä–º—É–ª—ã, —Å–≤–æ–π—Å—Ç–≤–∞
4. –†–µ—à–∏ –∑–∞–¥–∞—á—É —à–∞–≥ –∑–∞ —à–∞–≥–æ–º, –ø–æ–∫–∞–∑—ã–≤–∞—è –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
5. –î–ª—è –≥–µ–æ–º–µ—Ç—Ä–∏–∏ - —Å–¥–µ–ª–∞–π –º—ã—Å–ª–µ–Ω–Ω—ã–π —á–µ—Ä—Ç–µ–∂ –∏–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è
6. –ü—Ä–æ–≤–µ—Ä—å —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫ –≤ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è—Ö

–ü–æ—Å–ª–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0-3). –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
""",

    "economics": """
–¢—ã —ç–∫–æ–Ω–æ–º–∏—Å—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:

1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ä–∞–∑–¥–µ–ª —ç–∫–æ–Ω–æ–º–∏–∫–∏: –º–∏–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞, –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞, –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏–∫–∞
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ (—Å–ø—Ä–æ—Å/–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –∏–∑–¥–µ—Ä–∂–∫–∏, –í–í–ü, –∏–Ω—Ñ–ª—è—Ü–∏—è –∏ —Ç.–¥.)
3. –ü—Ä–∏–º–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ –∏ —Ç–µ–æ—Ä–∏–∏
4. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏
5. –†–∞—Å—Å–º–æ—Ç—Ä–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ –∏—Ö –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è
6. –ü—Ä–æ–≤–µ—Ä—å —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –ª–æ–≥–∏–∫—É –æ—Ç–≤–µ—Ç–∞

–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—ã–±–µ—Ä–∏ –∏ —É–∫–∞–∂–∏ –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –≤–µ—Ä–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
""",

    "psychology": """
–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞—É—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥:

1. –û–ø—Ä–µ–¥–µ–ª–∏ –æ–±–ª–∞—Å—Ç—å –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏: –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è, —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è, –∫–ª–∏–Ω–∏—á–µ—Å–∫–∞—è, —Ä–∞–∑–≤–∏–≤–∞—é—â–∞—è, –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è
2. –í—Å–ø–æ–º–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç–µ–æ—Ä–∏–∏ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
3. –ü—Ä–∏–º–µ–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã –Ω–∞—É—á–Ω–æ–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –≤ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏
4. –†–∞—Å—Å–º–æ—Ç—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –∏ –ø–æ–¥—Ö–æ–¥—ã
5. –û—Ç–¥–µ–ª–∏ –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã –æ—Ç –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
6. –ü—Ä–æ–≤–µ—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –∑–Ω–∞–Ω–∏—è–º

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –¥–∞–π –¢–û–õ–¨–ö–û —Ü–∏—Ñ—Ä—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0-3).
""",

    "health": """
–¢—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –∑–¥–æ—Ä–æ–≤—å–µ, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:

1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–µ–º—É: –∞–Ω–∞—Ç–æ–º–∏—è, —Ñ–∏–∑–∏–æ–ª–æ–≥–∏—è, –ø–∏—Ç–∞–Ω–∏–µ, –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã
2. –û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –Ω–∞—É—á–Ω–æ –¥–æ–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ñ–∞–∫—Ç—ã
3. –†–∞—Å—Å–º–æ—Ç—Ä–∏ –∞–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ —Ñ–∏–∑–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
4. –î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –ø–∏—Ç–∞–Ω–∏–∏ - –≤—Å–ø–æ–º–Ω–∏ –ø–∏—Ç–∞—Ç–µ–ª—å–Ω—ã–µ –≤–µ—â–µ—Å—Ç–≤–∞ –∏ –∏—Ö —Ñ—É–Ω–∫—Ü–∏–∏
5. –î–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ–º - –ø—Ä–∏–º–µ–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—ã
6. –ü—Ä–æ–≤–µ—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –∑–Ω–∞–Ω–∏—è–º

–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –≤–µ—Ä–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
""",

    "history": """
–¢—ã –∏—Å—Ç–æ—Ä–∏–∫-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ:

1. –û–ø—Ä–µ–¥–µ–ª–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–∏–æ–¥ –∏ —Ä–µ–≥–∏–æ–Ω
2. –í—Å–ø–æ–º–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è, –ª–∏—á–Ω–æ—Å—Ç–∏, –¥–∞—Ç—ã
3. –†–∞—Å—Å–º–æ—Ç—Ä–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
4. –£—á—Ç–∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã
5. –û—Ç–¥–µ–ª–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∫—Ç—ã –æ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–π
6. –ü—Ä–æ–≤–µ—Ä—å —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å

–í –∫–æ–Ω—Ü–µ —É–∫–∞–∂–∏ –¢–û–õ–¨–ö–û —Ü–∏—Ñ—Ä—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
""",

    "law": """
–¢—ã —é—Ä–∏—Å—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–∞–≤–æ–≤–æ–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ:

1. –û–ø—Ä–µ–¥–µ–ª–∏ –æ–±–ª–∞—Å—Ç—å –ø—Ä–∞–≤–∞: –∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ–µ, –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–µ, —É–≥–æ–ª–æ–≤–Ω–æ–µ, –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ
2. –í—ã–¥–µ–ª–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –ø–æ–Ω—è—Ç–∏—è –∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã
3. –ü—Ä–∏–º–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∞–≤–æ–≤—ã–µ –Ω–æ—Ä–º—ã –∏ –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç—ã
4. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–∞–∫—Ç—ã –∏ –∏—Ö —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é
5. –†–∞—Å—Å–º–æ—Ç—Ä–∏ –≤—Å–µ —Å—Ç–æ—Ä–æ–Ω—ã –ø—Ä–∞–≤–æ–≤–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏
6. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏—á–µ—Å–∫—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤

–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–π –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (0-3).
""",

    "engineering": """
–¢—ã –∏–Ω–∂–µ–Ω–µ—Ä-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç. –†–µ—à–∏ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—É—é –∑–∞–¥–∞—á—É, –∏—Å–ø–æ–ª—å–∑—É—è —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø–æ–¥—Ö–æ–¥:

1. –û–ø—Ä–µ–¥–µ–ª–∏ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—É—é –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É: –º–µ—Ö–∞–Ω–∏–∫–∞, —ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞, —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –∏ —Ç.–¥.
2. –í—ã–¥–µ–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
3. –í—Å–ø–æ–º–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ —Ñ–æ—Ä–º—É–ª—ã
4. –ü—Ä–∏–º–µ–Ω–∏ –º–µ—Ç–æ–¥ –ø–æ—à–∞–≥–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞
5. –ü—Ä–æ–≤–µ—Ä—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –æ—Å—É—â–µ—Å—Ç–≤–∏–º–æ—Å—Ç—å –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
6. –£—á—Ç–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

–ü–æ—Å–ª–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –≤–µ—Ä–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
""",

    "computer science": """
–¢—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º –Ω–∞—É–∫–∞–º. –†–µ—à–∏ –∑–∞–¥–∞—á—É –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ:

1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–µ–º—É: –∞–ª–≥–æ—Ä–∏—Ç–º—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–µ —Å–µ—Ç–∏, –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ–±–ª–µ–º—É –∏ –≤—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
3. –í—Å–ø–æ–º–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø—Ä–∏–Ω—Ü–∏–ø—ã
4. –ü—Ä–∏–º–µ–Ω–∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è
5. –î–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ - –ø–æ—à–∞–≥–æ–≤–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
6. –ü—Ä–æ–≤–µ—Ä—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –≤—ã–≤–æ–¥–æ–≤

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –¥–∞–π –¢–û–õ–¨–ö–û —Ü–∏—Ñ—Ä—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (0-3).
""",

    "business": """
–¢—ã –±–∏–∑–Ω–µ—Å-—ç–∫—Å–ø–µ—Ä—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –±–∏–∑–Ω–µ—Å-–≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ:

1. –û–ø—Ä–µ–¥–µ–ª–∏ –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ü–µ–ø—Ü–∏—é: –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥, —Ñ–∏–Ω–∞–Ω—Å—ã, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –±–∏–∑–Ω–µ—Å-–ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –º–æ–¥–µ–ª–∏
3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–∏—Ç—É–∞—Ü–∏—é —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
4. –†–∞—Å—Å–º–æ—Ç—Ä–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
5. –û—Ü–µ–Ω–∏ —Ä–∏—Å–∫–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
6. –ü—Ä–æ–≤–µ—Ä—å –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã—Ö —Ä–µ—à–µ–Ω–∏–π

–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ —É–∫–∞–∂–∏ –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
""",

    "philosophy": """
–¢—ã —Ñ–∏–ª–æ—Å–æ—Ñ-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ:

1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫—É—é –æ–±–ª–∞—Å—Ç—å: —ç–ø–∏—Å—Ç–µ–º–æ–ª–æ–≥–∏—è, —ç—Ç–∏–∫–∞, –º–µ—Ç–∞—Ñ–∏–∑–∏–∫–∞, –ª–æ–≥–∏–∫–∞, —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è –Ω–∞—É–∫–∏
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–µ –ø–æ–Ω—è—Ç–∏—è –∏ —Ç–µ–æ—Ä–∏–∏
3. –ü—Ä–∏–º–µ–Ω–∏ –º–µ—Ç–æ–¥—ã —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏–∏
4. –†–∞—Å—Å–º–æ—Ç—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –∏ –∏—Ö –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
5. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
6. –ü—Ä–æ–≤–µ—Ä—å –Ω–µ–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–æ—Å—Ç—å –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –≤—ã–≤–æ–¥–æ–≤

–í –∫–æ–Ω—Ü–µ –Ω–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ü–∏—Ñ—Ä—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
""",

    "other": """
–¢—ã —ç—Ä—É–¥–∏—Ç —Å —à–∏—Ä–æ–∫–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω—ã–π –ø–æ–¥—Ö–æ–¥:

1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –µ–≥–æ –æ–±—â—É—é —Ç–µ–º–∞—Ç–∏–∫—É
2. –í—Å–ø–æ–º–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä–∞–∑–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
3. –ü—Ä–∏–º–µ–Ω–∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
4. –†–∞—Å—Å–º–æ—Ç—Ä–∏ –≤–æ–ø—Ä–æ—Å —Å —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤
5. –ü—Ä–æ–≤–µ—Ä—å —Ñ–∞–∫—Ç—ã –∏ –ª–æ–≥–∏–∫—É
6. –ò—Å–∫–ª—é—á–∏ –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω—ã–µ –∏–ª–∏ –Ω–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã

–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–π –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0, 1, 2 –∏–ª–∏ 3).
"""
}


FEW_SHOT_PROMPTS = {
    "history": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏—Å—Ç–æ—Ä–∏–∏. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –í –∫–∞–∫–æ–º –≥–æ–¥—É –ø—Ä–æ–∏–∑–æ—à–ª–∞ –ö—É–ª–∏–∫–æ–≤—Å–∫–∞—è –±–∏—Ç–≤–∞?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. 1223 –≥–æ–¥
1. 1242 –≥–æ–¥  
2. 1380 –≥–æ–¥
3. 1480 –≥–æ–¥
–û—Ç–≤–µ—Ç: 2

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö—Ç–æ –±—ã–ª –ø–µ—Ä–≤—ã–º –∏–º–ø–µ—Ä–∞—Ç–æ—Ä–æ–º –†–æ—Å—Å–∏–∏?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ò–≤–∞–Ω –ì—Ä–æ–∑–Ω—ã–π
1. –ü–µ—Ç—Ä I
2. –ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ II
3. –ù–∏–∫–æ–ª–∞–π I
–û—Ç–≤–µ—Ç: 1""",

    "math": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ß–µ–º—É —Ä–∞–≤–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è 2x + 3y –ø—Ä–∏ x=2, y=4?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. 10
1. 12
2. 14
3. 16
–û—Ç–≤–µ—Ç: 3

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —É —Ñ—É–Ω–∫—Ü–∏–∏ f(x) = x¬≤?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. x
1. 2x
2. 2
3. 0
–û—Ç–≤–µ—Ç: 1""",

    "physics": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–∏–∑–∏–∫–µ. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –° –∫–∞–∫–æ–π —Å–∏–ª–æ–π –ø—Ä–∏—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è —Ç–µ–ª–æ –º–∞—Å—Å–æ–π 1 –∫–≥ –∫ –ó–µ–º–ª–µ?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. 1 –ù
1. 9.8 –ù
2. 10 –ù
3. 100 –ù
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–æ–π –∑–∞–∫–æ–Ω –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ó–∞–∫–æ–Ω –û–º–∞
1. –ó–∞–∫–æ–Ω –ù—å—é—Ç–æ–Ω–∞
2. –ó–∞–∫–æ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–∏–∏
3. –ó–∞–∫–æ–Ω –ê—Ä—Ö–∏–º–µ–¥–∞
–û—Ç–≤–µ—Ç: 2""",

    "psychology": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö—Ç–æ –æ—Å–Ω–æ–≤–∞–ª –ø—Å–∏—Ö–æ–∞–Ω–∞–ª–∏–∑?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ö–∞—Ä–ª –Æ–Ω–≥
1. –ó–∏–≥–º—É–Ω–¥ –§—Ä–µ–π–¥
2. –ò–≤–∞–Ω –ü–∞–≤–ª–æ–≤
3. –ê–±—Ä–∞—Ö–∞–º –ú–∞—Å–ª–æ—É
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–∏—Å—Å–æ–Ω–∞–Ω—Å?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ö–æ–Ω—Ñ–ª–∏–∫—Ç –º–µ–∂–¥—É –º—ã—Å–ª—è–º–∏ –∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏
1. –ù–∞—Ä—É—à–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
2. –î–µ–ø—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
3. –¢—Ä–µ–≤–æ–∂–Ω–æ–µ —Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
–û—Ç–≤–µ—Ç: 0""",

    "law": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–∞–≤—É. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–æ–π –∫–æ–¥–µ–∫—Å —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –≤ –†–æ—Å—Å–∏–∏?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –£–≥–æ–ª–æ–≤–Ω—ã–π –∫–æ–¥–µ–∫—Å
1. –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å
2. –¢—Ä—É–¥–æ–≤–æ–π –∫–æ–¥–µ–∫—Å
3. –ù–∞–ª–æ–≥–æ–≤—ã–π –∫–æ–¥–µ–∫—Å
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ –ø—Ä–µ–∑—É–º–ø—Ü–∏—è –Ω–µ–≤–∏–Ω–æ–≤–Ω–æ—Å—Ç–∏?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –û–±–≤–∏–Ω—è–µ–º—ã–π –¥–æ–ª–∂–µ–Ω –¥–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ—é –Ω–µ–≤–∏–Ω–æ–≤–Ω–æ—Å—Ç—å
1. –û–±–≤–∏–Ω—è–µ–º—ã–π —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–µ–≤–∏–Ω–æ–≤–Ω—ã–º, –ø–æ–∫–∞ –≤–∏–Ω–∞ –Ω–µ –¥–æ–∫–∞–∑–∞–Ω–∞
2. –°—É–¥—å—è –≤—Å–µ–≥–¥–∞ –ø—Ä–∞–≤
3. –ó–∞–∫–æ–Ω –æ–±—Ä–∞—Ç–Ω–æ–π —Å–∏–ª—ã –Ω–µ –∏–º–µ–µ—Ç
–û—Ç–≤–µ—Ç: 1""",

    "business": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–∑–Ω–µ—Å—É. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ SWOT-–∞–Ω–∞–ª–∏–∑?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ê–Ω–∞–ª–∏–∑ —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω, –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ —É–≥—Ä–æ–∑
1. –ê–Ω–∞–ª–∏–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
2. –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
3. –ê–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–æ–≤–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞
–û—Ç–≤–µ—Ç: 0

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç ROI?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. Return On Investment - –≤–æ–∑–≤—Ä–∞—Ç –Ω–∞ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏
1. Rate Of Interest - –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è —Å—Ç–∞–≤–∫–∞
2. Risk Of Inflation - —Ä–∏—Å–∫ –∏–Ω—Ñ–ª—è—Ü–∏–∏
3. Revenue Over Income - –¥–æ—Ö–æ–¥ –ø–æ–≤–µ—Ä—Ö –¥–æ—Ö–æ–¥–∞
–û—Ç–≤–µ—Ç: 0""",

    "biology": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–æ–ª–æ–≥–∏–∏. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–æ–π –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞–∑—ã–≤–∞—é—Ç —Ñ–æ—Ç–æ—Å–∏–Ω—Ç–µ–∑–æ–º?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –î—ã—Ö–∞–Ω–∏–µ —Ä–∞—Å—Ç–µ–Ω–∏–π
1. –ü–æ–≥–ª–æ—â–µ–Ω–∏–µ –≤–æ–¥—ã –∫–æ—Ä–Ω—è–º–∏
2. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–≤–µ—Ç–∞ –≤ —Ö–∏–º–∏—á–µ—Å–∫—É—é —ç–Ω–µ—Ä–≥–∏—é
3. –†–∞–∑–º–Ω–æ–∂–µ–Ω–∏–µ —Ä–∞—Å—Ç–µ–Ω–∏–π
–û—Ç–≤–µ—Ç: 2

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö—Ç–æ –æ—Ç–∫—Ä—ã–ª —Å—Ç—Ä—É–∫—Ç—É—Ä—É –î–ù–ö?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ú–µ–Ω–¥–µ–ª—å
1. –ü–∞–≤–ª–æ–≤
2. –£–æ—Ç—Å–æ–Ω –∏ –ö—Ä–∏–∫
3. –î–∞—Ä–≤–∏–Ω
–û—Ç–≤–µ—Ç: 2""",

    "engineering": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç—Å—è –≤ –û–º–∞—Ö?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ù–∞–ø—Ä—è–∂–µ–Ω–∏–µ
1. –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ
2. –¢–æ–∫
3. –ú–æ—â–Ω–æ—Å—Ç—å
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–æ–π –∑–∞–∫–æ–Ω –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ç–æ–∫–∞ –æ—Ç –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ó–∞–∫–æ–Ω –û–º–∞
1. –ó–∞–∫–æ–Ω –ù—å—é—Ç–æ–Ω–∞
2. –ó–∞–∫–æ–Ω –ê—Ä—Ö–∏–º–µ–¥–∞
3. –ó–∞–∫–æ–Ω –ü–∞—Å–∫–∞–ª—è
–û—Ç–≤–µ—Ç: 0""",

    "economics": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —ç–∫–æ–Ω–æ–º–∏–∫–µ. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ –∏–Ω—Ñ–ª—è—Ü–∏—è?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –†–æ—Å—Ç —Ü–µ–Ω –∏ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
1. –°–Ω–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω
2. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ü–µ–Ω
3. –†–æ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞
–û—Ç–≤–µ—Ç: 0

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç –í–í–ü?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –£—Ä–æ–≤–µ–Ω—å –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü—ã
1. –û–±—ä–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏ —É—Å–ª—É–≥
2. –£—Ä–æ–≤–µ–Ω—å –∏–Ω—Ñ–ª—è—Ü–∏–∏
3. –î–æ—Ö–æ–¥—ã –Ω–∞—Å–µ–ª–µ–Ω–∏—è
–û—Ç–≤–µ—Ç: 1""",

    "chemistry": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ö–∏–º–∏–∏. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∞—è —Ñ–æ—Ä–º—É–ª–∞ –≤–æ–¥—ã?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. H2O
1. CO2
2. NaCl
3. O2
–û—Ç–≤–µ—Ç: 0

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ pH?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –∫–∏—Å–ª–æ—Ç–Ω–æ—Å—Ç–∏
1. –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏
2. –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
3. –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –¥–∞–≤–ª–µ–Ω–∏—è
–û—Ç–≤–µ—Ç: 0""",

    "philosophy": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö—Ç–æ –∞–≤—Ç–æ—Ä "–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–∞"?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ê—Ä–∏—Å—Ç–æ—Ç–µ–ª—å
1. –ü–ª–∞—Ç–æ–Ω
2. –°–æ–∫—Ä–∞—Ç
3. –î–µ–∫–∞—Ä—Ç
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ "cogito ergo sum"?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. "–ú—ã—Å–ª—é, —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é"
1. "–ó–Ω–∞–Ω–∏–µ - —Å–∏–ª–∞"
2. "–ë—ã—Ç–∏–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–æ–∑–Ω–∞–Ω–∏–µ"
3. "–í—Å—ë —Ç–µ—á–µ—Ç, –≤—Å—ë –∏–∑–º–µ–Ω—è–µ—Ç—Å—è"
–û—Ç–≤–µ—Ç: 0""",

    "health": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–µ–¥–∏—Ü–∏–Ω–µ. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç —Ç–æ–Ω–æ–º–µ—Ç—Ä?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É —Ç–µ–ª–∞
1. –ê—Ä—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ
2. –£—Ä–æ–≤–µ–Ω—å —Å–∞—Ö–∞—Ä–∞ –≤ –∫—Ä–æ–≤–∏
3. –ß–∞—Å—Ç–æ—Ç—É –ø—É–ª—å—Å–∞
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–æ–π –≤–∏—Ç–∞–º–∏–Ω –≤—ã—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ–¥ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ–º —Å–æ–ª–Ω—Ü–∞?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –í–∏—Ç–∞–º–∏–Ω A
1. –í–∏—Ç–∞–º–∏–Ω C
2. –í–∏—Ç–∞–º–∏–Ω D
3. –í–∏—Ç–∞–º–∏–Ω B12
–û—Ç–≤–µ—Ç: 2""",

    "computer science": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–µ. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤:

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ –∞–ª–≥–æ—Ä–∏—Ç–º?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞
1. –ü—Ä–æ–≥—Ä–∞–º–º–∞ –Ω–∞ Python
2. –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
3. –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
–û—Ç–≤–µ—Ç: 2

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–æ–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–∑–¥–∞–ª –ì–≤–∏–¥–æ –≤–∞–Ω –†–æ—Å—Å—É–º?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. Java
1. Python
2. C++
3. JavaScript
–û—Ç–≤–µ—Ç: 1""",

    "other": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö –∑–Ω–∞–Ω–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –∏ –∫—Ä–∞—Ç–∫–æ.

–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∞—è —Å–∞–º–∞—è –¥–ª–∏–Ω–Ω–∞—è —Ä–µ–∫–∞ –≤ –º–∏—Ä–µ?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ê–º–∞–∑–æ–Ω–∫–∞
1. –ù–∏–ª
2. –Ø–Ω—Ü–∑—ã
3. –ú–∏—Å—Å–∏—Å–∏–ø–∏
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö—Ç–æ –Ω–∞–ø–∏—Å–∞–ª "–í–æ–π–Ω—É –∏ –º–∏—Ä"?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –î–æ—Å—Ç–æ–µ–≤—Å–∫–∏–π
1. –¢–æ–ª—Å—Ç–æ–π
2. –ß–µ—Ö–æ–≤
3. –¢—É—Ä–≥–µ–Ω–µ–≤
–û—Ç–≤–µ—Ç: 1"""
}


class LLM:
    def __init__(
        self,
        model_name="Qwen/Qwen2.5-14B-Instruct",
        device="cuda",
        _prompts=PROMPTS,
        _few_shot_prompts=FEW_SHOT_PROMPTS,
        model=None,
        tokenizer=None,
        quantization_config=None,
        debug=False,
        deep_debug=False,
        use_llm_parsing=True,
        use_selfcheck=False,
        llm_cot_generation=True,
        llm_few_shot_generation=True
    ) -> None:
        self.DEBUG = debug
        self.DEEP_DEBUG = deep_debug
        self.debug_logs = []
        self.USE_LLM_PARSING = use_llm_parsing
        self.USE_SELFCHECK = use_selfcheck
        self.LLM_COT_GENERATION = llm_cot_generation
        self.LLM_FEW_SHOT_GENERATION = llm_few_shot_generation
        try:
            self.prompts = _prompts
            self.few_shot_prompts = _few_shot_prompts
            self.model_name = model_name
            self.device = device if torch.cuda.is_available() and device == "cuda" else "cpu"
            print(f"üèãÔ∏è‚Äç‚ôÇÔ∏è –ú–æ–¥–µ–ª—å: {self.model_name}")
            print(f"üñ• –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
            print(f"‚öôÔ∏è  CoT –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: {'–í–ö–õ' if llm_cot_generation else '–í–´–ö–õ'}")
            print(f"‚öôÔ∏è  Few-shot –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: {'–í–ö–õ' if llm_few_shot_generation else '–í–´–ö–õ'}")
            if model is not None and tokenizer is not None:
                print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä")
                self.model = model
                self.tokenizer = tokenizer
                return
            print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ {self.model_name}...")
            self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            if quantization_config is None:
                quantization_config = BitsAndBytesConfig(
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_compute_dtype=torch.float16,
                    bnb_4bit_use_double_quant=True,
                    load_in_4bit=True,
                )
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                quantization_config=quantization_config,
                device_map="auto",
                trust_remote_code=True
            )
            print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            print("–ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–µ–∑ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è...")
            try:
                self.tokenizer = AutoTokenizer.from_pretrained(
                    model_name,
                    trust_remote_code=True
                )
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token

                self.model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    device_map="auto",
                    torch_dtype=torch.float16,
                    trust_remote_code=True
                )
                print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –±–µ–∑ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è")
            except Exception as e2:
                print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e2}")
                raise e2

    def get_answer_method(self, use_selfcheck=None):
        if use_selfcheck is None:
            use_selfcheck = self.USE_SELFCHECK
        return self.generate_answer_selfcheck if use_selfcheck else self.generate_answer

    def generate_answer(
        self,
        question:str,
        encoded_options,
        category:str,
        dramatic:bool = True,
        tokens:int = 1000,
        temperature:float = 0.1,
        few_shot = True,
        use_llm_parsing=None,
        use_selfcheck=None,
        llm_cot_generation=None,
        llm_few_shot_generation=None,
        force_diversity: bool = False
    )->int:

        if use_llm_parsing is None:
            use_llm_parsing = self.USE_LLM_PARSING
        if use_selfcheck is None:
            use_selfcheck = self.USE_SELFCHECK
        if llm_cot_generation is None:
            llm_cot_generation = self.LLM_COT_GENERATION
        if llm_few_shot_generation is None:
            llm_few_shot_generation = self.LLM_FEW_SHOT_GENERATION

        if use_selfcheck:
            return self.generate_answer_selfcheck(
                question=question,
                encoded_options=encoded_options,
                category=category,
                dramatic=dramatic,
                tokens=tokens,
                temperature=temperature,
                use_llm_parsing=use_llm_parsing,
                llm_cot_generation=llm_cot_generation,
                llm_few_shot_generation=llm_few_shot_generation
            )

        self._log("generate_answer", "–Ω–∞—á–∞–ª–æ", {
            "category": category,
            "question_len": len(question),
            "options_raw_preview": str(encoded_options)[:200],
            "temperature": temperature,
            "use_llm_parsing": use_llm_parsing,
            "use_selfcheck": use_selfcheck,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation,
            "force_diversity": force_diversity
        }, "DEBUG")

        options = self._options_parser(encoded_options)
        self._log("generate_answer", "—Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –æ–ø—Ü–∏–∏", {
            "count": len(options),
            "first_3": options[:3] if len(options) > 3 else options
        }, "DEBUG")

        if len(options) <= 1 and options[0] == "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã":
            self._log("generate_answer", "–û–®–ò–ë–ö–ê: –Ω–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞", {
                "question": question[:200]
            }, "DEBUG")
            return 0

        result = self.generate_prompt(
            question=question,
            encoded_options=options,
            topic=category,
            drammatic=dramatic,
            few_shot=few_shot,
            llm_cot_generation=llm_cot_generation,
            llm_few_shot_generation=llm_few_shot_generation
        )

        if result is None:
            self._log("generate_answer", "–ø—Ä–æ–º–ø—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω", None, "DEBUG")
            return 0
        system_prompt, user_prompt = result

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        inputs = self.tokenizer(text, return_tensors="pt").to(self.device)

        generation_kwargs = {
            "input_ids": inputs.input_ids,
            "attention_mask": inputs.attention_mask,
            "max_new_tokens": tokens,
            "pad_token_id": self.tokenizer.pad_token_id,
        }

        if force_diversity:
            generation_kwargs["temperature"] = temperature
            generation_kwargs["do_sample"] = True
            generation_kwargs["top_p"] = 0.9
        elif temperature > 0:
            generation_kwargs["temperature"] = temperature
            generation_kwargs["do_sample"] = True

            if category in ['history', 'philosophy', 'law', 'psychology', 'other']:
                generation_kwargs["top_p"] = 0.9
            elif category in ['math', 'physics', 'engineering', 'computer science', 'chemistry']:
                if temperature < 0.3:
                    generation_kwargs["do_sample"] = False
        else:

            generation_kwargs["temperature"] = 0.1
            generation_kwargs["do_sample"] = False

        self._log("generate_answer", "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", {
            "temperature": generation_kwargs.get("temperature", 0),
            "do_sample": generation_kwargs.get("do_sample", False),
            "top_p": generation_kwargs.get("top_p", None),
            "category": category,
            "force_diversity": force_diversity
        }, "DEBUG")

        with torch.no_grad():
            generated_ids = self.model.generate(**generation_kwargs)

        response = self.tokenizer.decode(
            generated_ids[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        )

        parsed = self.parse_answer_index(response, use_llm_parsing=use_llm_parsing)

        self._log_response(
            "MAIN_MODEL_RESPONSE",
            response,
            parsed,
            None,
            {
                "category": category,
                "question": question[:100],
                "use_llm_parsing": use_llm_parsing,
                "use_selfcheck": use_selfcheck,
                "llm_cot_generation": llm_cot_generation,
                "llm_few_shot_generation": llm_few_shot_generation,
                "temperature": generation_kwargs.get("temperature", 0),
                "do_sample": generation_kwargs.get("do_sample", False),
                "response_length": len(response)
            }
        )

        self._log("generate_answer", "–∑–∞–≤–µ—Ä—à–µ–Ω–æ", {
            "parsed": parsed,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation,
            "generation_params": {
                "temp": generation_kwargs.get("temperature", 0),
                "do_sample": generation_kwargs.get("do_sample", False)
            }
        }, "DEBUG")

        return parsed

    def generate_answer_selfcheck(
        self,
        question:str,
        encoded_options,
        category:str,
        dramatic:bool = True,
        tokens:int = 1000,
        temperature:float = 0.1,
        use_llm_parsing=None,
        use_selfcheck=None,
        llm_cot_generation=None,
        llm_few_shot_generation=None
    )->int:

        if use_llm_parsing is None:
            use_llm_parsing = self.USE_LLM_PARSING
        if use_selfcheck is None:
            use_selfcheck = self.USE_SELFCHECK
        if llm_cot_generation is None:
            llm_cot_generation = self.LLM_COT_GENERATION
        if llm_few_shot_generation is None:
            llm_few_shot_generation = self.LLM_FEW_SHOT_GENERATION

        self._log("generate_answer_selfcheck", "–Ω–∞—á–∞–ª–æ", {
            "category": category,
            "use_llm_parsing": use_llm_parsing,
            "use_selfcheck": use_selfcheck,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        main_response = self.generate_answer(
            question=question,
            encoded_options=encoded_options,
            category=category,
            dramatic=dramatic,
            tokens=tokens,
            temperature=temperature,
            use_llm_parsing=use_llm_parsing,
            use_selfcheck=False,
            llm_cot_generation=llm_cot_generation,
            llm_few_shot_generation=llm_few_shot_generation
        )

        selfcheck = self._generate_selfcheck_prompt(
            question=question,
            topic=category,
            encoded_options=encoded_options,
            predicted_answer=main_response,
            drammatic=dramatic,
            use_llm_parsing=use_llm_parsing,
            llm_cot_generation=llm_cot_generation,
            llm_few_shot_generation=llm_few_shot_generation
        )

        if selfcheck is None:
            self._log("generate_answer_selfcheck", "selfcheck –ø—Ä–æ–º–ø—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω", None, "DEBUG")
            return main_response

        system_prompt, user_prompt = selfcheck

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        inputs = self.tokenizer(text, return_tensors="pt").to(self.device)

        with torch.no_grad():
            generated_ids = self.model.generate(
                inputs.input_ids,
                attention_mask=inputs.attention_mask,
                max_new_tokens=tokens,
                temperature=temperature,
                do_sample=False,
                pad_token_id=self.tokenizer.pad_token_id,
            )

        response = self.tokenizer.decode(
            generated_ids[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        )

        verified = self.parse_answer_index(response, use_llm_parsing=use_llm_parsing)

        self._log_response(
            "SELFCHECK_RESPONSE",
            response,
            verified,
            None,
            {
                "category": category,
                "main_response": main_response,
                "verified": verified,
                "changed": main_response != verified,
                "use_llm_parsing": use_llm_parsing,
                "use_selfcheck": use_selfcheck,
                "llm_cot_generation": llm_cot_generation,
                "llm_few_shot_generation": llm_few_shot_generation
            }
        )

        self._log("generate_answer_selfcheck", "–∑–∞–≤–µ—Ä—à–µ–Ω–æ", {
            "main": main_response,
            "verified": verified,
            "changed": main_response != verified,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        return verified

    def ensemble_vote(
        self,
        question,
        encoded_options,
        category,
        n_votes=3,
        temperatures=[0.1, 0.5, 0.9],
        use_llm_parsing=None,
        use_selfcheck=None,
        llm_cot_generation=None,
        llm_few_shot_generation=None,
        force_diversity = True
    ):
        if use_llm_parsing is None:
            use_llm_parsing = self.USE_LLM_PARSING
        if use_selfcheck is None:
            use_selfcheck = self.USE_SELFCHECK
        if llm_cot_generation is None:
            llm_cot_generation = self.LLM_COT_GENERATION
        if llm_few_shot_generation is None:
            llm_few_shot_generation = self.LLM_FEW_SHOT_GENERATION

        self._log("ensemble_vote", "–Ω–∞—á–∞–ª–æ", {
            "category": category,
            "n_votes": n_votes,
            "temperatures": temperatures[:n_votes],
            "use_llm_parsing": use_llm_parsing,
            "use_selfcheck": use_selfcheck,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        votes = []
        for i, temp in enumerate(temperatures[:n_votes]):
            self._log("ensemble_vote", f"–≥–æ–ª–æ—Å {i+1}", {
                "temperature": temp,
                "llm_cot_generation": llm_cot_generation,
                "llm_few_shot_generation": llm_few_shot_generation
            }, "DEEP_DEBUG")

            answer = self.generate_answer(
                question=question,
                encoded_options=encoded_options,
                category=category,
                temperature=temp,
                tokens=1000,
                use_llm_parsing=use_llm_parsing,
                use_selfcheck=use_selfcheck,
                llm_cot_generation=llm_cot_generation,
                llm_few_shot_generation=llm_few_shot_generation,
                force_diversity=force_diversity
            )
            parsed = self.parse_answer_index(str(answer))
            votes.append(parsed)

            self._log("ensemble_vote", f"–≥–æ–ª–æ—Å {i+1} —Ä–µ–∑—É–ª—å—Ç–∞—Ç", {
                "answer": answer,
                "parsed": parsed,
                "temperature": temp,
                "llm_cot_generation": llm_cot_generation,
                "llm_few_shot_generation": llm_few_shot_generation
            }, "DEEP_DEBUG")

        from collections import Counter
        vote_counts = Counter(votes)
        most_common = vote_counts.most_common(1)[0]

        self._log("ensemble_vote", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç", {
            "votes": votes,
            "distribution": dict(vote_counts),
            "final": most_common[0],
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        return most_common[0], dict(vote_counts)

    def ask_with_verification(
        self,
        question,
        encoded_options,
        category,
        temperature=0.1,
        use_llm_parsing=None,
        use_selfcheck=None,
        llm_cot_generation=None,
        llm_few_shot_generation=None
    ):
        if use_llm_parsing is None:
            use_llm_parsing = self.USE_LLM_PARSING
        if use_selfcheck is None:
            use_selfcheck = self.USE_SELFCHECK
        if llm_cot_generation is None:
            llm_cot_generation = self.LLM_COT_GENERATION
        if llm_few_shot_generation is None:
            llm_few_shot_generation = self.LLM_FEW_SHOT_GENERATION

        self._log("ask_with_verification", "–Ω–∞—á–∞–ª–æ", {
            "category": category,
            "temperature": temperature,
            "use_llm_parsing": use_llm_parsing,
            "use_selfcheck": use_selfcheck,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        first_answer = self.generate_answer(
            question=question,
            encoded_options=encoded_options,
            category=category,
            temperature=temperature,
            tokens=400,
            use_llm_parsing=use_llm_parsing,
            use_selfcheck=use_selfcheck,
            llm_cot_generation=llm_cot_generation,
            llm_few_shot_generation=llm_few_shot_generation
        )

        self._log("ask_with_verification", "–ø–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç", {
            "first_answer": first_answer,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEEP_DEBUG")

        res = self._generate_selfcheck_prompt(
            question=question,
            topic=category,
            encoded_options=encoded_options,
            predicted_answer=first_answer,
            drammatic=True,
            use_llm_parsing=use_llm_parsing,
            llm_cot_generation=llm_cot_generation,
            llm_few_shot_generation=llm_few_shot_generation
        )

        if res is None:
            self._log("ask_with_verification", "–æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ selfcheck", None, "DEBUG")
            return 0, 0, 0

        system_prompt, user_prompt = res
        check_response = self.direct_prompt(
            user_prompt=user_prompt,
            system_prompt=system_prompt,
            tokens=300,
            temperature=0.1
        )

        verified_answer = self.parse_answer_index(check_response, use_llm_parsing=use_llm_parsing)

        weight = 1.5 if first_answer == verified_answer else 0.7

        self._log("ask_with_verification", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç", {
            "first": first_answer,
            "verified": verified_answer,
            "weight": weight,
            "agreement": first_answer == verified_answer,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        return verified_answer, weight, first_answer

    def confidence_ensemble_vote(
        self,
        question,
        encoded_options,
        category,
        n_runs=3,
        temperatures=[0.1, 0.3, 0.5],
        use_llm_parsing=None,
        use_selfcheck=None,
        llm_cot_generation=None,
        llm_few_shot_generation=None
    ):
        if use_llm_parsing is None:
            use_llm_parsing = self.USE_LLM_PARSING
        if use_selfcheck is None:
            use_selfcheck = self.USE_SELFCHECK
        if llm_cot_generation is None:
            llm_cot_generation = self.LLM_COT_GENERATION
        if llm_few_shot_generation is None:
            llm_few_shot_generation = self.LLM_FEW_SHOT_GENERATION

        self._log("confidence_ensemble_vote", "–Ω–∞—á–∞–ª–æ", {
            "category": category,
            "n_runs": n_runs,
            "temperatures": temperatures[:n_runs],
            "use_llm_parsing": use_llm_parsing,
            "use_selfcheck": use_selfcheck,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        results = []

        for i, temp in enumerate(temperatures[:n_runs]):
            self._log("confidence_ensemble_vote", f"–∑–∞–ø—É—Å–∫ {i+1}", {
                "temperature": temp,
                "llm_cot_generation": llm_cot_generation,
                "llm_few_shot_generation": llm_few_shot_generation
            }, "DEEP_DEBUG")

            answer, weight, first_answer = self.ask_with_verification(
                question=question,
                encoded_options=encoded_options,
                category=category,
                temperature=temp,
                use_llm_parsing=use_llm_parsing,
                use_selfcheck=use_selfcheck,
                llm_cot_generation=llm_cot_generation,
                llm_few_shot_generation=llm_few_shot_generation
            )

            results.append({
                'answer': answer,
                'weight': weight,
                'first_answer': first_answer,
                'agreement': first_answer == answer
            })

            self._log("confidence_ensemble_vote", f"–∑–∞–ø—É—Å–∫ {i+1} —Ä–µ–∑—É–ª—å—Ç–∞—Ç", {
                "answer": answer,
                "weight": weight,
                "agreement": first_answer == answer,
                "llm_cot_generation": llm_cot_generation,
                "llm_few_shot_generation": llm_few_shot_generation
            }, "DEEP_DEBUG")

        weighted_counts = {}
        for res in results:
            ans = res['answer']
            weight = res['weight']
            if ans in weighted_counts:
                weighted_counts[ans] += weight
            else:
                weighted_counts[ans] = weight

        best_answer = max(weighted_counts.items(), key=lambda x: x[1])
        total_weight = sum(res['weight'] for res in results)
        final_confidence = best_answer[1] / total_weight if total_weight > 0 else 0

        agreement_rate = sum(1 for res in results if res['agreement']) / len(results) if len(results) > 0 else 0

        self._log("confidence_ensemble_vote", "—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç", {
            "best_answer": best_answer[0],
            "confidence": final_confidence,
            "agreement_rate": agreement_rate,
            "weighted_counts": weighted_counts,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        return best_answer[0], weighted_counts, final_confidence, agreement_rate


    def evaluate_dataframe(
        self,
        df,
        question_column="question",
        options_column="options",
        category_column="category",
        answer_column="true_answer",
        method:Literal[
            "ensemble_vote",
            "generate_answer",
            "confidence_ensemble_vote",
            "generate_answer_selfcheck"
        ]="ensemble_vote",
        method_kwargs=None,
        use_llm_parsing=None,
        use_selfcheck=None,
        llm_cot_generation=None,
        llm_few_shot_generation=None
    ):
        if method_kwargs is None:
            method_kwargs = {}

        if use_llm_parsing is None:
            use_llm_parsing = self.USE_LLM_PARSING
        if use_selfcheck is None:
            use_selfcheck = self.USE_SELFCHECK
        if llm_cot_generation is None:
            llm_cot_generation = self.LLM_COT_GENERATION
        if llm_few_shot_generation is None:
            llm_few_shot_generation = self.LLM_FEW_SHOT_GENERATION

        self._log("evaluate_dataframe", "–Ω–∞—á–∞–ª–æ", {
            "rows": len(df),
            "method": method,
            "columns": df.columns.tolist(),
            "has_answer_column": answer_column in df.columns,
            "has_actual_answers": answer_column in df.columns and df[answer_column].notna().any()
        }, "DEBUG")

        predictions = []
        processing_times = []
        category_results = {}

        has_actual_answers = False
        if answer_column in df.columns:
            has_actual_answers = df[answer_column].notna().any()
            if has_actual_answers:
                print(f"‚úÖ –í –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –æ—Ç–≤–µ—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ ({df[answer_column].notna().sum()}/{len(df)})")
            else:
                print("‚ÑπÔ∏è  –ö–æ–ª–æ–Ω–∫–∞ 'true_answer' –µ—Å—Ç—å, –Ω–æ –≤—Å–µ –æ—Ç–≤–µ—Ç—ã –ø—É—Å—Ç—ã–µ (—Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è)")
        pbar = tqdm(total=len(df), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤")

        for idx, row in df.iterrows():
            try:
                start_time = time.time()

                question = str(row[question_column])
                options = row[options_column]
                category = str(row[category_column])

                expected_answer = None
                if answer_column in df.columns and pd.notna(row[answer_column]):
                    expected_answer = self.parse_answer_index(str(row[answer_column]))

                self._log("evaluate_dataframe", f"—Å—Ç—Ä–æ–∫–∞ {idx}", {
                    "category": category,
                    "has_expected": expected_answer is not None,
                    "expected": expected_answer,
                    "question_preview": question[:50]
                }, "DEEP_DEBUG")

                method_kwargs_with_defaults = {
                    "use_llm_parsing": use_llm_parsing,
                    "use_selfcheck": use_selfcheck,
                    "llm_cot_generation": llm_cot_generation,
                    "llm_few_shot_generation": llm_few_shot_generation,
                    **method_kwargs
                }

                if method == "generate_answer":
                    predicted = self.generate_answer(
                        question=question,
                        encoded_options=options,
                        category=category,
                        **method_kwargs_with_defaults
                    )
                elif method == "generate_answer_selfcheck":
                    predicted = self.generate_answer_selfcheck(
                        question=question,
                        encoded_options=options,
                        category=category,
                        **method_kwargs_with_defaults
                    )
                elif method == "ensemble_vote":
                    predicted, vote_dist = self.ensemble_vote(
                        question=question,
                        encoded_options=options,
                        category=category,
                        **method_kwargs_with_defaults
                    )

                    if self.DEEP_DEBUG:
                        print(f"ensemble_vote —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {vote_dist}")
                elif method == "confidence_ensemble_vote":
                    predicted, weighted_counts, confidence, agreement = self.confidence_ensemble_vote(
                        question=question,
                        encoded_options=options,
                        category=category,
                        **method_kwargs_with_defaults
                    )

                    if self.DEEP_DEBUG:
                        print(f"confidence_ensemble_vote: confidence={confidence}, agreement={agreement}")
                else:
                    raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥: {method}")

                predictions.append(predicted)
                processing_time = time.time() - start_time
                processing_times.append(processing_time)

                if category not in category_results:
                    category_results[category] = {
                        'total': 0, 'correct': 0, 'predictions': [], 'truths': []
                    }

                category_results[category]['total'] += 1
                category_results[category]['predictions'].append(predicted)
                if expected_answer is not None:
                    category_results[category]['truths'].append(expected_answer)
                    predicted_parsed = self.parse_answer_index(str(predicted))

                    if predicted_parsed == expected_answer:
                        category_results[category]['correct'] += 1

                        if self.DEEP_DEBUG:
                            print(f"‚úì –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ {predicted_parsed}, –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_answer}")
                    else:
                        if self.DEEP_DEBUG:
                            print(f"‚úó –û—à–∏–±–∫–∞: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ {predicted_parsed}, –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_answer}")

                pbar.update(1)
                postfix_info = {
                    '–∫–∞—Ç–µ–≥–æ—Ä–∏—è': category[:10],
                    '–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ': self.parse_answer_index(str(predicted))
                }
                if expected_answer is not None:
                    postfix_info['–æ—Ç–≤–µ—Ç'] = expected_answer
                pbar.set_postfix(postfix_info)

            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {idx}: {e}")

                self._log("evaluate_dataframe", f"–æ—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {idx}", {
                    "error": str(e),
                    "llm_cot_generation": llm_cot_generation,
                    "llm_few_shot_generation": llm_few_shot_generation
                }, "DEBUG")

                predictions.append(0)
                processing_times.append(0)
                pbar.update(1)

        pbar.close()

        self._log("evaluate_dataframe", "–∑–∞–≤–µ—Ä—à–µ–Ω–æ", {
            "total_rows": len(df),
            "predictions_made": len(predictions),
            "has_actual_answers": has_actual_answers,
            "method": method
        }, "DEBUG")

        results_df = df.copy()
        results_df['predicted'] = predictions
        results_df['processing_time'] = processing_times
        
        if has_actual_answers:
            try:
                results_df['predicted_parsed'] = results_df['predicted'].apply(
                    lambda x: self.parse_answer_index(str(x)) if pd.notna(x) else 0
                )
                results_df['answer_parsed'] = results_df[answer_column].apply(
                    lambda x: self.parse_answer_index(str(x)) if pd.notna(x) else 0
                )
                results_df['is_correct'] = results_df['predicted_parsed'] == results_df['answer_parsed']

                if self.DEBUG:
                    correct = results_df['is_correct'].sum()
                    total = len(results_df)
                    accuracy = correct / total if total > 0 else 0
                    print(f"üìä –ò—Ç–æ–≥ —Ç–æ—á–Ω–æ—Å—Ç–∏: {correct}/{total} –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö ({accuracy:.2%})")

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {e}")
                results_df['is_correct'] = False
        else:
            print("‚ÑπÔ∏è  –û—Ç–≤–µ—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–µ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è")

        metrics = self._calculate_metrics(
            results_df,
            answer_column if has_actual_answers else None,
            category_results,
            processing_times,
            method
        )

        metrics['use_llm_parsing'] = use_llm_parsing
        metrics['use_selfcheck'] = use_selfcheck
        metrics['llm_cot_generation'] = llm_cot_generation
        metrics['llm_few_shot_generation'] = llm_few_shot_generation
        metrics['has_actual_answers'] = has_actual_answers

        if self.DEBUG and has_actual_answers:
            accuracy = metrics.get('accuracy', 0)
            print(f"üìà –§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")

        return results_df, metrics

    def generate_prompt(
        self,
        question,
        topic,
        encoded_options,
        drammatic:bool = True,
        drammatic_prompt = "–ù–∞ —Ç–µ–±—è –≤–æ–∑–ª–æ–∂–µ–Ω–∞ –æ–≥—Ä–æ–º–Ω–∞—è –Ω–∞–¥–µ–∂–¥–∞ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –º–æ—é –∂–∏–∑–Ω—å –∏ —Ä–µ–ø—É—Ç–∞—Ü–∏—é, –Ω–µ –ø–æ–¥–≤–µ–¥–∏ –Ω–∞—Å",
        few_shot = True,
        llm_cot_generation=True,
        llm_few_shot_generation=True
    ):
        self._log("generate_prompt", "–Ω–∞—á–∞–ª–æ", {
            "topic": topic,
            "few_shot": few_shot,
            "encoded_options_raw": str(encoded_options)[:200],
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEEP_DEBUG")

        options = self._options_parser(options=encoded_options)

        self._log("generate_prompt", "—Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –æ–ø—Ü–∏–∏", {
            "count": len(options),
            "options_preview": options[:3] if options else []
        }, "DEBUG")

        if not options or (len(options) == 1 and options[0] == "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã"):
            self._log("generate_prompt", "–í–ù–ò–ú–ê–ù–ò–ï: –Ω–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞!", {
                "raw_input": str(encoded_options)[:500]
            }, "DEBUG")
            return None

        base_prompt = self.prompts.get(topic,
            "–¢—ã - –æ–ø—ã—Ç–Ω—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç —à–∏—Ä–æ–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è. –û—Ç–≤–µ—Ç—å –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–±–µ –≤–æ–ø—Ä–æ—Å, –≤—ã–±—Ä–∞–≤ –∏–Ω–¥–µ–∫—Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (–Ω–∞—á–∏–Ω–∞—è —Å –Ω—É–ª—è)"
            "–î–∞–π –≤ –æ—Ç–≤–µ—Ç–µ —Ç–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å, –Ω–µ –¥–∞–≤–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"
            "–î–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –æ–±–¥—É–º–∞–π –∫–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞, –ø–æ–¥—É–º–∞–π, –ø–æ—á–µ–º—É –æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º"
        )


        cot_section = ""
        if llm_cot_generation:
            cot_instruction = self.generate_cot_instruction(
                question=question,
                topic=topic,
                encoded_options=encoded_options,
                max_tokens=400
            )

            if cot_instruction:
                cot_section = f"""

–ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –†–ï–®–ï–ù–ò–Ø (CHAIN OF THOUGHT):
–†–µ—à–∏ –∑–∞–¥–∞—á—É, —Å–ª–µ–¥—É—è —ç—Ç–∏–º —à–∞–≥–∞–º:
{cot_instruction}

–í–ê–ñ–ù–û: –ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–ø–∏—à–∏ "–û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–´–ô –û–¢–í–ï–¢: [–∏–Ω–¥–µ–∫—Å]"
"""
            else:
                self._log("generate_prompt", "CoT –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback", None, "DEBUG")
                cot_section = """

–ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –†–ï–®–ï–ù–ò–Ø:
1. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π –≤–æ–ø—Ä–æ—Å
2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞
3. –ò—Å–∫–ª—é—á–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
4. –í—ã–±–µ—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
5. –ù–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
"""


        few_shot_text = ""
        if few_shot:
            if llm_few_shot_generation:
                few_shot_text = self.generate_contextual_few_shot(
                    question=question,
                    topic=topic,
                    encoded_options=encoded_options,
                    num_examples=2
                )
            else:
                few_shot_text = self.few_shot_prompts.get(topic,
                    """–í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤:
–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∞—è —Å–∞–º–∞—è –¥–ª–∏–Ω–Ω–∞—è —Ä–µ–∫–∞ –≤ –º–∏—Ä–µ?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –ê–º–∞–∑–æ–Ω–∫–∞
1. –ù–∏–ª
2. –Ø–Ω—Ü–∑—ã
3. –ú–∏—Å—Å–∏—Å–∏–ø–∏
–û—Ç–≤–µ—Ç: 1

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: –ö—Ç–æ –Ω–∞–ø–∏—Å–∞–ª "–í–æ–π–Ω—É –∏ –º–∏—Ä"?
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
0. –î–æ—Å—Ç–æ–µ–≤—Å–∫–∏–π
1. –¢–æ–ª—Å—Ç–æ–π
2. –ß–µ—Ö–æ–≤
3. –¢—É—Ä–≥–µ–Ω–µ–≤
–û—Ç–≤–µ—Ç: 1""" if few_shot else ""
                )

        system_prompt = f"""
{base_prompt}

{f"–ü—Ä–∏–º–µ—Ä—ã —Ä–µ—à–µ–Ω–∏—è –ø–æ–¥–æ–±–Ω—ã—Ö –∑–∞–¥–∞—á:\n{few_shot_text}\n" if few_shot_text else ""}
{cot_section if llm_cot_generation else ""}

–û–ë–†–ê–¢–ò –í–ù–ò–ú–ê–ù–ò–ï:
- –í —ç—Ç–æ–º –≤–æ–ø—Ä–æ—Å–µ {len(options)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (–∏–Ω–¥–µ–∫—Å—ã –æ—Ç 0 –¥–æ {len(options)-1})
- –í –æ—Ç–≤–µ—Ç–µ –¥–∞–π –¢–û–õ–¨–ö–û –∏–Ω–¥–µ–∫—Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
- –ù–µ –ø–∏—à–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê: [–∏–Ω–¥–µ–∫—Å] (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2)
"""

        options_text = "\n".join([f"{ind}. {opt}" for ind, opt in enumerate(options)])

        user_prompt = f"""
–í–æ–ø—Ä–æ—Å: {question}

–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
{options_text}

{drammatic_prompt if drammatic else ""}

–û—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å):"""

        self._log("generate_prompt", "—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω", {
            "options_count": len(options),
            "question_preview": question[:100],
            "first_option": options[0][:100] if options else "–Ω–µ—Ç",
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation,
            "has_cot": bool(cot_section),
            "has_few_shot": bool(few_shot_text)
        }, "DEBUG")

        if self.DEEP_DEBUG:
            print("\n[DEEP_DEBUG] generate_prompt - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç:")
            print(f"System preview: {system_prompt[:300]}...")
            print(f"\nUser preview: {user_prompt[:300]}...")

        return system_prompt, user_prompt

    def _generate_selfcheck_prompt(
        self,
        question,
        topic,
        encoded_options,
        predicted_answer,
        drammatic:bool = True,
        drammatic_prompt = "–ù–∞ —Ç–µ–±—è –≤–æ–∑–ª–æ–∂–µ–Ω–∞ –æ–≥—Ä–æ–º–Ω–∞—è –Ω–∞–¥–µ–∂–¥–∞ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –º–æ—é –∂–∏–∑–Ω—å –∏ —Ä–µ–ø—É—Ç–∞—Ü–∏—é, –Ω–µ –ø–æ–¥–≤–µ–¥–∏ –Ω–∞—Å",
        few_shot = True,
        use_llm_parsing=True,
        llm_cot_generation=True,
        llm_few_shot_generation=True
    ):
        self._log("_generate_selfcheck_prompt", "–Ω–∞—á–∞–ª–æ", {
            "topic": topic,
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEEP_DEBUG")

        options = self._options_parser(options=encoded_options)
        if not options:
            self._log("_generate_selfcheck_prompt", "–æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–ø—Ü–∏–π", None, "DEBUG")
            return None

        predicted_idx = self.parse_answer_index(
            str(predicted_answer),
            use_llm_parsing=use_llm_parsing
        )

        option_text = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç"
        if 0 <= predicted_idx < len(options):
            option_text = options[predicted_idx]

        self._log("_generate_selfcheck_prompt", "–∏–Ω–¥–µ–∫—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", {
            "raw": str(predicted_answer)[:50],
            "parsed": predicted_idx,
            "option_text": option_text[:50],
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEEP_DEBUG")

        base_prompt = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–µ –æ—Ç–≤–µ—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—Ç–≤–µ—Ç –¥—Ä—É–≥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞.
–ï—Å–ª–∏ –æ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π - –≤–µ—Ä–Ω–∏ —Ç–æ—Ç –∂–µ –∏–Ω–¥–µ–∫—Å. –ï—Å–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π - –Ω–∞–π–¥–∏ –∏ –≤–µ—Ä–Ω–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å."""

        if llm_cot_generation:
            base_prompt += "\n\n–ò–°–ü–û–õ–¨–ó–£–ô –¶–ï–ü–û–ß–ö–£ –†–ê–°–°–£–ñ–î–ï–ù–ò–ô:\n"
            base_prompt += "1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å\n"
            base_prompt += "2. –ü—Ä–æ–≤–µ—Ä—å –æ—Ç–≤–µ—Ç –∫–æ–ª–ª–µ–≥–∏ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–æ–ø—Ä–æ—Å—É\n"
            base_prompt += "3. –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è, –Ω–∞–π–¥–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ\n"
            base_prompt += "4. –î–∞–π –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ '–û–¢–í–ï–¢: [–∏–Ω–¥–µ–∫—Å]'"

        if few_shot:
            base_prompt += """
–ü—Ä–∏–º–µ—Ä 1:
–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∞—è —Å—Ç–æ–ª–∏—Ü–∞ –§—Ä–∞–Ω—Ü–∏–∏?
–í–∞—Ä–∏–∞–Ω—Ç—ã:
0. –õ–æ–Ω–¥–æ–Ω
1. –ë–µ—Ä–ª–∏–Ω
2. –ü–∞—Ä–∏–∂
3. –ú–∞–¥—Ä–∏–¥
–û—Ç–≤–µ—Ç –∫–æ–ª–ª–µ–≥–∏: 2
–¢–≤–æ–π –æ—Ç–≤–µ—Ç: 2

–ü—Ä–∏–º–µ—Ä 2:
–í–æ–ø—Ä–æ—Å: 2 + 2 = ?
–í–∞—Ä–∏–∞–Ω—Ç—ã:
0. 3
1. 4
2. 5
3. 6
–û—Ç–≤–µ—Ç –∫–æ–ª–ª–µ–≥–∏: 0
–¢–≤–æ–π –æ—Ç–≤–µ—Ç: 1"""

        system_prompt = f"{base_prompt}"

        options_text = "\n".join([f"{i}. {opt}" for i, opt in enumerate(options)])

        user_prompt = f"""
–í–æ–ø—Ä–æ—Å: {question}
–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤:
{options_text}
–û—Ç–≤–µ—Ç –∫–æ–ª–ª–µ–≥–∏: {predicted_idx} ({option_text})
{drammatic_prompt if drammatic else ""}
–¢–≤–æ–π –æ—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å):
–û–ë–†–ê–¢–ò –í–ù–ò–ú–ê–ù–ò–ï - –í –û–¢–í–ï–¢–ï –¢–ï–ë–ï –ù–£–ñ–ù–û –î–ê–¢–¨ –û–î–ò–ù –ò–ù–î–ï–ö–°
–ù–ï –ü–ò–®–ò –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–• –†–ê–°–°–£–ñ–î–ï–ù–ò–ô
"""

        self._log("_generate_selfcheck_prompt", "—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω", {
            "options_count": len(options),
            "llm_cot_generation": llm_cot_generation,
            "llm_few_shot_generation": llm_few_shot_generation
        }, "DEBUG")

        return system_prompt, user_prompt

    def _log(self, method, message, data=None, level="DEBUG"):
        if level == "DEBUG" and not self.DEBUG:
            return
        if level == "DEEP_DEBUG" and not self.DEEP_DEBUG:
            return

        log_entry = {
            "timestamp": time.time(),
            "method": method,
            "message": message,
            "data": data,
            "level": level
        }
        self.debug_logs.append(log_entry)

        if self.DEBUG or self.DEEP_DEBUG:
            print(f"[{level}] {method}: {message}")
            if data and self.DEEP_DEBUG:
                print(f"    –î–∞–Ω–Ω—ã–µ: {data}")

    def _log_response(self, stage, raw_response, parsed, expected=None, metadata=None):
        if not self.DEEP_DEBUG:
            return

        print(f"\n{'='*80}")
        print(f"[DEEP_DEBUG] {stage}")
        print(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç ({len(raw_response)} chars):")
        print(f"{raw_response[:500]}...")
        print(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ: {parsed}")
        if expected is not None:
            print(f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected}")
            print(f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {parsed == expected}")
        if metadata:
            print(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata}")
        print(f"{'='*80}\n")

        log_entry = {
            "timestamp": time.time(),
            "stage": stage,
            "raw_response": raw_response[:1000],
            "parsed": parsed,
            "expected": expected,
            "metadata": metadata
        }
        self.debug_logs.append(log_entry)

    def _options_parser(self, options):
        self._log("_options_parser", "–Ω–∞—á–∞–ª–æ", {
            "raw_input": str(options)[:200],
            "type": type(options)
        }, "DEEP_DEBUG")


        if isinstance(options, list):
            self._log("_options_parser", "—É–∂–µ —Å–ø–∏—Å–æ–∫", {"len": len(options), "first_3": options[:3]}, "DEEP_DEBUG")
            return options

        original_input = str(options)


        if isinstance(options, str):

            text = original_input.strip()


            if text.startswith('[') and text.endswith(']'):
                try:

                    json_text = text.replace("'", '"')
                    parsed = json.loads(json_text)
                    if isinstance(parsed, list):
                        self._log("_options_parser", "JSON –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω", {"len": len(parsed)}, "DEBUG")
                        return parsed
                except json.JSONDecodeError as e:
                    self._log("_options_parser", "JSON –æ—à–∏–±–∫–∞", {"error": str(e)}, "DEBUG")


            if text.startswith('[') and text.endswith(']'):

                content = text[1:-1].strip()
                self._log("_options_parser", "—Ñ–æ—Ä–º–∞—Ç —Å –ø—Ä–æ–±–µ–ª–∞–º–∏", {"content_preview": content[:100]}, "DEEP_DEBUG")

                items = []
                current_item = ""
                in_quotes = False
                quote_char = None

                i = 0
                while i < len(content):
                    char = content[i]

                    if char in ['"', "'"]:
                        if not in_quotes:

                            in_quotes = True
                            quote_char = char
                            current_item += char
                        elif char == quote_char:

                            in_quotes = False
                            current_item += char
                            items.append(current_item)
                            current_item = ""


                            i += 1
                            while i < len(content) and content[i] in [' ', '\n', '\t']:
                                i += 1
                            continue
                        else:
                            current_item += char
                    elif char == ' ' and not in_quotes:

                        if current_item:
                            items.append(current_item)
                            current_item = ""
                    else:
                        current_item += char

                    i += 1


                if current_item:
                    items.append(current_item)


                cleaned_items = []
                for item in items:
                    item = item.strip()
                    if item:
                        if (item.startswith('"') and item.endswith('"')) or \
                        (item.startswith("'") and item.endswith("'")):
                            item = item[1:-1]

                        item = item.replace('\\"', '"').replace("\\'", "'").replace('\\n', '\n')
                        cleaned_items.append(item)

                if cleaned_items:
                    self._log("_options_parser", "—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω", {
                        "count": len(cleaned_items),
                        "first_3": cleaned_items[:3]
                    }, "DEBUG")
                    return cleaned_items


        if isinstance(options, str) and ',' in options:
            try:

                parts = []
                current = ""
                in_quotes = False
                quote_char = None

                for char in options:
                    if char in ['"', "'"]:
                        if not in_quotes:
                            in_quotes = True
                            quote_char = char
                        elif char == quote_char:
                            in_quotes = False
                        current += char
                    elif char == ',' and not in_quotes:
                        parts.append(current.strip())
                        current = ""
                    else:
                        current += char

                if current:
                    parts.append(current.strip())


                cleaned_parts = []
                for part in parts:
                    part = part.strip()
                    if part:
                        if (part.startswith('"') and part.endswith('"')) or \
                        (part.startswith("'") and part.endswith("'")):
                            part = part[1:-1]
                        cleaned_parts.append(part)

                if cleaned_parts:
                    self._log("_options_parser", "—Ä–∞–∑–¥–µ–ª–∏–ª–∏ –ø–æ –∑–∞–ø—è—Ç—ã–º", {
                        "count": len(cleaned_parts),
                        "first_3": cleaned_parts[:3]
                    }, "DEBUG")
                    return cleaned_parts
            except Exception as e:
                self._log("_options_parser", "–æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –ø–æ –∑–∞–ø—è—Ç—ã–º", {"error": str(e)}, "DEBUG")


        if isinstance(options, str) and len(options) > 10:
            self._log("_options_parser", "–ø—Ä–æ–±—É–µ–º LLM –ø–∞—Ä—Å–∏–Ω–≥", None, "DEBUG")
            llm_parsed = self._llm_parse_options(options)
            if llm_parsed:
                return llm_parsed


        self._log("_options_parser", "–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å", {
            "original_length": len(original_input),
            "original_preview": original_input[:200]
        }, "DEBUG")

        return ["–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã"]

    def _llm_parse_options(self, options_text):
        """–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ LLM –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–ª–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ–ø—Ü–∏–π"""
        try:
            system_prompt = """–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö. –ò–∑–≤–ª–µ–∫–∏ —Å–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    –¢–µ–∫—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö: JSON, Python —Å–ø–∏—Å–æ–∫, –∏–ª–∏ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ.
    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫.

    –ü—Ä–∏–º–µ—Ä 1:
    –í—Ö–æ–¥: "['–í–∞—Ä–∏–∞–Ω—Ç A' '–í–∞—Ä–∏–∞–Ω—Ç B' '–í–∞—Ä–∏–∞–Ω—Ç C']"
    –í—ã—Ö–æ–¥: ["–í–∞—Ä–∏–∞–Ω—Ç A", "–í–∞—Ä–∏–∞–Ω—Ç B", "–í–∞—Ä–∏–∞–Ω—Ç C"]

    –ü—Ä–∏–º–µ—Ä 2:
    –í—Ö–æ–¥: "['–Æ–∂–Ω–∞—è –ê–º–µ—Ä–∏–∫–∞' '–Æ–∂–Ω–∞—è –ê–∑–∏—è' '–°–µ–≤–µ—Ä–Ω–∞—è –ê—Ñ—Ä–∏–∫–∞']"
    –í—ã—Ö–æ–¥: ["–Æ–∂–Ω–∞—è –ê–º–µ—Ä–∏–∫–∞", "–Æ–∂–Ω–∞—è –ê–∑–∏—è", "–°–µ–≤–µ—Ä–Ω–∞—è –ê—Ñ—Ä–∏–∫–∞"]

    –ü—Ä–∏–º–µ—Ä 3:
    –í—Ö–æ–¥: "['–í–µ—Ä–Ω–æ, –ù–µ–≤–µ—Ä–Ω–æ' '–ù–µ —É–∫–∞–∑–∞–Ω–æ, –ù–µ —É–∫–∞–∑–∞–Ω–æ']"
    –í—ã—Ö–æ–¥: ["–í–µ—Ä–Ω–æ, –ù–µ–≤–µ—Ä–Ω–æ", "–ù–µ —É–∫–∞–∑–∞–Ω–æ, –ù–µ —É–∫–∞–∑–∞–Ω–æ"]

    –ü–†–ê–í–ò–õ–ê:
    1. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π –≤–∞–ª–∏–¥–Ω—ã–π JSON
    2. –¢–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
    3. –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    4. –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å - –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ []"""

            user_prompt = f"""–ò–∑–≤–ª–µ–∫–∏ —Å–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞:

    –¢–µ–∫—Å—Ç: {options_text}

    JSON —Å–ø–∏—Å–æ–∫:"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            inputs = self.tokenizer(text, return_tensors="pt").to(self.device)

            with torch.no_grad():
                generated_ids = self.model.generate(
                    inputs.input_ids,
                    attention_mask=inputs.attention_mask,
                    max_new_tokens=500,
                    temperature=0.1,
                    do_sample=False,
                    pad_token_id=self.tokenizer.pad_token_id
                )

            llm_response = self.tokenizer.decode(
                generated_ids[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            )

            self._log("_llm_parse_options", "LLM –æ—Ç–≤–µ—Ç", {"response": llm_response[:200]}, "DEBUG")


            try:
                parsed = json.loads(llm_response)
                if isinstance(parsed, list):
                    self._log("_llm_parse_options", "—É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ", {"count": len(parsed)}, "DEBUG")
                    return parsed
            except json.JSONDecodeError:

                import re
                json_match = re.search(r'\[.*\]', llm_response, re.DOTALL)
                if json_match:
                    try:
                        parsed = json.loads(json_match.group())
                        if isinstance(parsed, list):
                            self._log("_llm_parse_options", "–Ω–∞—à–ª–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ", {"count": len(parsed)}, "DEBUG")
                            return parsed
                    except:
                        pass

            return []

        except Exception as e:
            self._log("_llm_parse_options", "–æ—à–∏–±–∫–∞", {"error": str(e)}, "DEBUG")
            return []

    def generate_cot_instruction(
        self,
        question: str,
        topic: str,
        encoded_options,
        max_tokens: int = 1000
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ CoT –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.

        Returns:
            str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è CoT –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        self._log("generate_cot_instruction", "–Ω–∞—á–∞–ª–æ", {
            "topic": topic,
            "question_len": len(question),
            "max_tokens": max_tokens
        }, "DEBUG")

        options = self._options_parser(encoded_options)
        if not options or (len(options) == 1 and options[0] == "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã"):
            self._log("generate_cot_instruction", "–Ω–µ—Ç –æ–ø—Ü–∏–π", None, "DEBUG")
            return ""

        options_text = "\n".join([f"{i}. {opt}" for i, opt in enumerate(options)])

        system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–µ—Ç–æ–¥–∏–∫–µ Chain of Thought (CoT).
    –°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–æ—à–∞–≥–æ–≤—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ó–ê–î–ê–ß–ò.

    –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
    1. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ö–û–ù–ö–†–ï–¢–ù–û–ô –¥–ª—è –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏
    2. –ò—Å–ø–æ–ª—å–∑—É–π –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —à–∞–≥–∏ (1., 2., 3., ...)
    3. –í–∫–ª—é—á–∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    4. –£—á–∏—Ç—ã–≤–∞–π —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞–¥–∞—á–∏
    5. –ó–∞–≤–µ—Ä—à–∏ —á–µ—Ç–∫–∏–º —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞

    –§–û–†–ú–ê–¢ –í–´–í–û–î–ê:
    –ù–∞—á–Ω–∏ —Å—Ä–∞–∑—É —Å –ø–æ—à–∞–≥–æ–≤–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π."""

        user_prompt = f"""–°–æ–∑–¥–∞–π Chain of Thought –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è —Ä–µ—à–µ–Ω–∏—è:

    –ö–ê–¢–ï–ì–û–†–ò–Ø: {topic}

    –í–û–ü–†–û–°:
    {question}

    –í–ê–†–ò–ê–ù–¢–´ –û–¢–í–ï–¢–û–í (–≤—Å–µ–≥–æ {len(options)}):
    {options_text}

    –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø–æ–º–æ—á—å —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–µ—à–∏—Ç—å —ç—Ç—É –∑–∞–¥–∞—á—É.
    –ò–Ω–¥–µ–∫—Å—ã –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: –æ—Ç 0 –¥–æ {len(options)-1}.

    CoT –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:"""

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            inputs = self.tokenizer(text, return_tensors="pt").to(self.device)

            with torch.no_grad():
                generated_ids = self.model.generate(
                    inputs.input_ids,
                    attention_mask=inputs.attention_mask,
                    max_new_tokens=max_tokens,
                    temperature=0.3,
                    do_sample=False,
                    pad_token_id=self.tokenizer.pad_token_id,
                )

            cot_instruction = self.tokenizer.decode(
                generated_ids[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            ).strip()

            self._log("generate_cot_instruction", "CoT —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞", {
                "length": len(cot_instruction),
                "preview": cot_instruction[:200]
            }, "DEBUG")

            if self.DEEP_DEBUG:
                print(f"\n[DEEP_DEBUG] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è CoT –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:")
                print(f"{cot_instruction}")
                print("-" * 80)

            return cot_instruction

        except Exception as e:
            self._log("generate_cot_instruction", "–æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", {"error": str(e)}, "DEBUG")
            return ""

    def generate_contextual_few_shot(
        self,
        question: str,
        topic: str,
        encoded_options,
        num_examples: int = 2,
        max_tokens_per_example: int = 1000
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç few-shot –ø—Ä–∏–º–µ—Ä—ã, —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–º–µ–∂–Ω—ã–µ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º.

        Args:
            question: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å (–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º–∞—Ç–∏–∫–∏ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏)
            topic: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –≤–æ–ø—Ä–æ—Å–∞
            encoded_options: –í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
            num_examples: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens_per_example: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –ø—Ä–∏–º–µ—Ä

        Returns:
            str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ few-shot –ø—Ä–∏–º–µ—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç—Ä–æ–∫–∏
        """
        self._log("generate_contextual_few_shot", "–Ω–∞—á–∞–ª–æ", {
            "topic": topic,
            "num_examples": num_examples,
            "question_preview": question[:200]
        }, "DEBUG")

        options = self._options_parser(encoded_options)
        num_options = len(options) if options and options[0] != "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã" else 4

        question_complexity = "—Å—Ä–µ–¥–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏" if len(question) > 100 else "–±–∞–∑–æ–≤–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"
        options_complexity = f"{num_options} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤" if num_options > 4 else "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"

        system_prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é few-shot –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è LLM –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É "{topic}"
    –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–º–µ–∂–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã.

    –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ü–†–ò–ú–ï–†–ê–ú:
    1. –¢–ï–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –°–ú–ï–ñ–ù–û–°–¢–¨: –ü—Ä–∏–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–∑ —Ç–æ–π –∂–µ —É–∑–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–∏, —á—Ç–æ –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å
    2. –°–õ–û–ñ–ù–û–°–¢–¨: –ü—Ä–∏–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–æ–π –∂–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    3. –§–û–†–ú–ê–¢: –ö–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
    - –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ
    - –í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤ (–æ—Ç {max(3, num_options-2)} –¥–æ {min(10, num_options+2)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)
    - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∏–Ω–¥–µ–∫—Å–æ–º (—Ä–æ–≤–Ω–æ –æ–¥–∏–Ω)
    4. –°–¢–†–£–ö–¢–£–†–ê: –û–¥–∏–Ω –ø—Ä–∏–º–µ—Ä = –æ–¥–∏–Ω –±–ª–æ–∫ —Å —á–µ—Ç–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π

    –§–û–†–ú–ê–¢ –í–´–í–û–î–ê –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞:
    –ü—Ä–∏–º–µ—Ä [N]:
    –í–æ–ø—Ä–æ—Å: [—Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞]
    –í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
    0. [–≤–∞—Ä–∏–∞–Ω—Ç 0]
    1. [–≤–∞—Ä–∏–∞–Ω—Ç 1]
    ...
    [N]. [–≤–∞—Ä–∏–∞–Ω—Ç N]
    –û—Ç–≤–µ—Ç: [–∏–Ω–¥–µ–∫—Å]

    –ù–µ –ø–∏—à–∏ –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ –ø—Ä–∏–º–µ—Ä–æ–≤."""

        question_analysis = f"""
    –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –í–û–ü–†–û–° (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º–∞—Ç–∏–∫–∏ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏):
    {question}

    –û–ü–ò–°–ê–ù–ò–ï –û–†–ò–ì–ò–ù–ê–õ–ê:
    - –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {topic}
    - –°–ª–æ–∂–Ω–æ—Å—Ç—å: {question_complexity}
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {options_complexity}
    - –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Ç–µ–º–∞—Ç–∏–∫–∞: {self._extract_topic_keywords(question, topic)}
    """

        user_prompt = f"""{question_analysis}

    –°–æ–∑–¥–∞–π {num_examples} —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–º–µ–∂–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è few-shot –æ–±—É—á–µ–Ω–∏—è.

    –£–ß–¢–ò:
    1. –¢–µ–º–∞—Ç–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–∫–æ–π –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É
    2. –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ–π
    3. –í–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞: –ø—Ä–∏–º–µ—Ä–Ω–æ {num_options} (–æ—Ç {max(3, num_options-2)} –¥–æ {min(10, num_options+2)})
    4. –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
    5. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–º–∏ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏

    –ù–∞—á–Ω–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã:"""

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            inputs = self.tokenizer(text, return_tensors="pt").to(self.device)

            with torch.no_grad():
                generated_ids = self.model.generate(
                    inputs.input_ids,
                    attention_mask=inputs.attention_mask,
                    max_new_tokens=max_tokens_per_example * num_examples,
                    temperature=0.4,
                    do_sample=True,
                    top_p=0.9,
                    pad_token_id=self.tokenizer.pad_token_id,
                )

            few_shot_examples = self.tokenizer.decode(
                generated_ids[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            ).strip()

            formatted_examples = self._validate_and_format_few_shot(few_shot_examples, topic, num_options)

            self._log("generate_contextual_few_shot", "–ø—Ä–∏–º–µ—Ä—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã", {
                "original_topic": topic,
                "generated_length": len(formatted_examples),
                "num_examples_found": formatted_examples.count("–ü—Ä–∏–º–µ—Ä"),
                "preview": formatted_examples[:300]
            }, "DEBUG")

            if self.DEEP_DEBUG:
                print(f"\n[DEEP_DEBUG] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ few-shot –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è '{topic}':")
                print("-" * 80)
                print(formatted_examples)
                print("-" * 80)

            return formatted_examples

        except Exception as e:
            self._log("generate_contextual_few_shot", "–æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", {"error": str(e)}, "DEBUG")
            return ""

    def _extract_topic_keywords(self, question: str, topic: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É–∑–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–∏"""
        keywords = []

        if topic == 'math':
            math_terms = ['–≥–æ–º–æ–º–æ—Ä—Ñ–∏–∑–º', '—è–¥—Ä–æ', '–∏–Ω—ä–µ–∫—Ç–∏–≤–Ω—ã–π', '–∫–æ–ª—å—Ü–æ', '–∏–¥–µ–∞–ª', '—É—Ä–∞–≤–Ω–µ–Ω–∏–µ',
                        '–ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è', '–∏–Ω—Ç–µ–≥—Ä–∞–ª', '–º–∞—Ç—Ä–∏—Ü–∞', '–≤–µ–∫—Ç–æ—Ä', '—Ç–µ–æ—Ä–µ–º–∞', '–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ']
            keywords = [term for term in math_terms if term in question.lower()]

        elif topic == 'physics':
            physics_terms = ['—Å–∫–æ—Ä–æ—Å—Ç—å', '—É—Å–∫–æ—Ä–µ–Ω–∏–µ', '—Å–∏–ª–∞', '—ç–Ω–µ—Ä–≥–∏—è', '–∑–∞—Ä—è–¥', '–≤–æ–ª–Ω–∞',
                            '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞', '–¥–∞–≤–ª–µ–Ω–∏–µ', '–æ–ø—Ç–∏–∫–∞', '–º–µ—Ö–∞–Ω–∏–∫–∞', '—ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ']
            keywords = [term for term in physics_terms if term in question.lower()]

        elif topic == 'history':
            history_terms = ['–≥–æ–¥', '–≤–µ–∫', '–≤–æ–π–Ω–∞', '—Ä–µ–≤–æ–ª—é—Ü–∏—è', '–¥–æ–≥–æ–≤–æ—Ä', '–∏–º–ø–µ—Ä–∞—Ç–æ—Ä',
                            '—Å—Ä–∞–∂–µ–Ω–∏–µ', '—Ä–µ—Ñ–æ—Ä–º–∞', '—Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—è', '–ø–µ—Ä–∏–æ–¥', '—Å–æ–±—ã—Ç–∏–µ']
            keywords = [term for term in history_terms if term in question.lower()]

        if not keywords:
            words = question.lower().split()
            stop_words = {'—ç—Ç–æ—Ç', '–≤–æ–ø—Ä–æ—Å', '–æ—Ç–Ω–æ—Å–∏—Ç—Å—è', '—Å–ª–µ–¥—É—é—â–µ–π', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏', '–∫–∞–∫–æ–π', '—á—Ç–æ', '–∫–∞–∫'}
            keywords = [w for w in words if len(w) > 4 and w not in stop_words][:5]

        return ", ".join(keywords[:3]) if keywords else "–æ–±—â–∞—è —Ç–µ–º–∞—Ç–∏–∫–∞"

    def _validate_and_format_few_shot(self, examples_text: str, topic: str, expected_options: int) -> str:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ few-shot –ø—Ä–∏–º–µ—Ä—ã"""
        lines = examples_text.strip().split('\n')
        formatted = []
        current_example = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if line.startswith(('–ü—Ä–∏–º–µ—Ä', '–ø—Ä–∏–º–µ—Ä', 'EXAMPLE', 'example')):
                if current_example:
                    formatted_example = self._format_single_example(current_example, topic, expected_options)
                    if formatted_example:
                        formatted.append(formatted_example)
                    current_example = []
                current_example.append(line)
            elif current_example:
                current_example.append(line)

        if current_example:
            formatted_example = self._format_single_example(current_example, topic, expected_options)
            if formatted_example:
                formatted.append(formatted_example)

        if not formatted:
            fallback = self._create_fallback_examples(topic, expected_options)
            return fallback

        return "\n\n".join(formatted)

    def _format_single_example(self, example_lines: list, topic: str, expected_options: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω few-shot –ø—Ä–∏–º–µ—Ä"""
        example_text = "\n".join(example_lines)

        has_question = any('–≤–æ–ø—Ä–æ—Å:' in line.lower() for line in example_lines)
        has_options = any('–≤–∞—Ä–∏–∞–Ω—Ç' in line.lower() for line in example_lines)
        has_answer = any('–æ—Ç–≤–µ—Ç:' in line.lower() for line in example_lines)

        if not (has_question and has_options and has_answer):
            return ""

        option_lines = [line for line in example_lines if re.match(r'^\d+\.', line.strip())]
        num_options = len(option_lines)

        if abs(num_options - expected_options) > 3 and expected_options > 3:
            return ""
        return example_text

    def _create_fallback_examples(self, topic: str, num_options: int) -> str:
        """–°–æ–∑–¥–∞–µ—Ç fallback –ø—Ä–∏–º–µ—Ä—ã –µ—Å–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å"""
        self._log("_create_fallback_examples", "—Å–æ–∑–¥–∞–µ–º fallback", {
            "topic": topic,
            "num_options": num_options
        }, "DEBUG")


        fallbacks = self.few_shot_prompts
        if topic in fallbacks.keys():
            return fallbacks[topic]

        return f"""–ü—Ä–∏–º–µ—Ä 1:
    –í–æ–ø—Ä–æ—Å: –ü—Ä–∏–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ –ø–æ —Ç–µ–º–µ {topic}
    –í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞:
    0. –í–∞—Ä–∏–∞–Ω—Ç A
    1. –í–∞—Ä–∏–∞–Ω—Ç B
    2. –í–∞—Ä–∏–∞–Ω—Ç C
    {'' if num_options <= 3 else '3. –í–∞—Ä–∏–∞–Ω—Ç D\n' + '\n'.join([f'{i}. –í–∞—Ä–∏–∞–Ω—Ç {chr(65+i)}' for i in range(4, min(8, num_options))])}
    –û—Ç–≤–µ—Ç: 0"""

    def llm_parse_answer(self, raw_response: str) -> int:
        self._log("llm_parse_answer", "–Ω–∞—á–∞–ª–æ", {"raw_len": len(raw_response)}, "DEEP_DEBUG")

        system_prompt = """–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é —á–∏—Å–µ–ª. –ò–∑–≤–ª–µ–∫–∏ –ß–ò–°–õ–û –∏–∑ —Ç–µ–∫—Å—Ç–∞.
–ü—Ä–∏–º–µ—Ä 1:
–¢–µ–∫—Å—Ç: "–û—Ç–≤–µ—Ç: 2. –≠—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ç–æ–º—É —á—Ç–æ..."
–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ: 2

–ü—Ä–∏–º–µ—Ä 2:
–¢–µ–∫—Å—Ç: "–Ø —Å—á–∏—Ç–∞—é, —á—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Ç—Ä–µ—Ç–∏–π"
–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ: 2

–ü—Ä–∏–º–µ—Ä 3:
–¢–µ–∫—Å—Ç: "–í–∞—Ä–∏–∞–Ω—Ç –ê –∫–∞–∂–µ—Ç—Å—è –≤–µ—Ä–Ω—ã–º"
–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ: 0

–ü—Ä–∏–º–µ—Ä 4:
–¢–µ–∫—Å—Ç: "–ù–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: 5"
–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ: 4

–ü–†–ê–í–ò–õ–ê:
1. –ò–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ (0, 1, 2, 3, ...)
2. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∏—Å–µ–ª - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ
3. –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –±—É–∫–≤–∞ (A=0, B=1, C=2, D=3)
4. –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –∏–∑–≤–ª–µ—á—å - –≤–æ–∑–≤—Ä–∞—â–∞–π 0
5. –¢–æ–ª—å–∫–æ —á–∏—Å–ª–æ, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞"""

        user_prompt = f"""–ò–∑–≤–ª–µ–∫–∏ —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞:

–¢–µ–∫—Å—Ç: {raw_response}

–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ:"""

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            inputs = self.tokenizer(text, return_tensors="pt").to(self.device)

            with torch.no_grad():
                generated_ids = self.model.generate(
                    inputs.input_ids,
                    attention_mask=inputs.attention_mask,
                    max_new_tokens=300,
                    temperature=0.1,
                    do_sample=False,
                    pad_token_id=self.tokenizer.pad_token_id
                )

            llm_parsed = self.tokenizer.decode(
                generated_ids[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            )

            self._log("llm_parse_answer", "LLM –æ—Ç–≤–µ—Ç", {"llm_parsed": llm_parsed}, "DEEP_DEBUG")

            regex_parsed = self._regex_parse_answer(llm_parsed)

            self._log("llm_parse_answer", "—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç", {
                "raw_response_len": len(raw_response),
                "llm_parsed": llm_parsed,
                "regex_parsed": regex_parsed
            }, "DEBUG")

            return regex_parsed

        except Exception as e:
            self._log("llm_parse_answer", "–æ—à–∏–±–∫–∞", {"error": str(e)}, "DEBUG")
            return 0

    def _regex_parse_answer(self, text: str) -> int:
        import re

        text = str(text).strip()

        if not text:
            return 0

        try:
            num = int(text)
            return num
        except:
            pass

        patterns = [
            r'^\s*(\d+)\s*$',
            r'–æ—Ç–≤–µ—Ç[:\s]*(\d+)',
            r'—á–∏—Å–ª–æ[:\s]*(\d+)',
            r'–Ω–æ–º–µ—Ä[:\s]*(\d+)',
            r'\b(\d+)\b',
        ]

        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    num = int(match.group(1))
                    return num
                except:
                    continue

        letter_match = re.search(r'\b([a-d])\b', text, re.IGNORECASE)
        if letter_match:
            letter = letter_match.group(1).upper()
            return ord(letter) - ord('A')

        return 0

    def parse_answer_index(self, answer_text: str, use_llm_parsing=True) -> int:
        self._log("parse_answer_index", "–Ω–∞—á–∞–ª–æ", {"raw": str(answer_text)[:100], "use_llm_parsing": use_llm_parsing}, "DEEP_DEBUG")

        if not answer_text:
            self._log("parse_answer_index", "–ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç", None, "DEBUG")
            return 0

        answer_text = str(answer_text).strip()

        try:
            num = int(answer_text)
            self._log("parse_answer_index", "–ø—Ä—è–º–æ–µ —á–∏—Å–ª–æ", {"num": num}, "DEBUG")
            return num
        except:
            pass

        if use_llm_parsing and len(answer_text) > 10:
            llm_result = self.llm_parse_answer(answer_text)
            self._log("parse_answer_index", "LLM –ø–∞—Ä—Å–∏–Ω–≥", {"llm_result": llm_result}, "DEBUG")

            if llm_result != 0:
                return llm_result

        regex_result = self._regex_parse_answer(answer_text)
        self._log("parse_answer_index", "—Ä–µ–≥—É–ª—è—Ä–∫–∏", {"regex_result": regex_result}, "DEBUG")

        return regex_result

    def direct_prompt(
        self,
        user_prompt:str,
        system_prompt:str,
        tokens:int = 1000,
        temperature:float = 0.1,
        few_shot = True
    ):
        self._log("direct_prompt", "–Ω–∞—á–∞–ª–æ", {
            "user_len": len(user_prompt),
            "system_len": len(system_prompt),
            "temperature": temperature
        }, "DEEP_DEBUG")

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)

        self._log("direct_prompt", "—à–∞–±–ª–æ–Ω –ø—Ä–∏–º–µ–Ω–µ–Ω", {"input_length": len(text)}, "DEEP_DEBUG")

        inputs = self.tokenizer(text, return_tensors="pt").to(self.device)

        with torch.no_grad():
            generated_ids = self.model.generate(
                inputs.input_ids,
                attention_mask=inputs.attention_mask,
                max_new_tokens=tokens,
                temperature=temperature,
                do_sample=False,
                pad_token_id=self.tokenizer.pad_token_id
            )

        response = self.tokenizer.decode(
            generated_ids[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        )

        self._log("direct_prompt", "–ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç", {"response_length": len(response)}, "DEBUG")

        if self.DEEP_DEBUG:
            print(f"[DEEP_DEBUG] direct_prompt response ({len(response)} chars):")
            print(f"{response[:500]}...")

        return response

    def get_debug_logs(self):
        return self.debug_logs

    def clear_debug_logs(self):
        self.debug_logs = []

    def save_debug_logs(self, filename="llm_debug_logs.json"):
        import json
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(self.debug_logs, f, ensure_ascii=False, indent=2)
        print(f"–õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def print_debug_summary(self):
        if not self.DEBUG and not self.DEEP_DEBUG:
            print("–û—Ç–ª–∞–¥–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞")
            return

        print(f"\n{'='*60}")
        print("–°–í–û–î–ö–ê –û–¢–õ–ê–î–ö–ò LLM")
        print(f"{'='*60}")
        print(f"–í—Å–µ–≥–æ –ª–æ–≥–æ–≤: {len(self.debug_logs)}")

        if self.debug_logs:
            methods = {}
            levels = {}
            for log in self.debug_logs:
                method = log.get("method", "unknown")
                level = log.get("level", "unknown")
                methods[method] = methods.get(method, 0) + 1
                levels[level] = levels.get(level, 0) + 1

            print("\n–í—ã–∑–æ–≤—ã –º–µ—Ç–æ–¥–æ–≤:")
            for method, count in sorted(methods.items()):
                print(f"  {method}: {count}")

            print("\n–£—Ä–æ–≤–Ω–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:")
            for level, count in sorted(levels.items()):
                print(f"  {level}: {count}")

            print(f"\nDEBUG: {self.DEBUG}")
            print(f"DEEP_DEBUG: {self.DEEP_DEBUG}")


    def _calculate_metrics(
        self,
        results_df,
        answer_column,
        category_results,
        processing_times,
        method
    ):
        prediction_column = 'answer' if 'answer' in results_df.columns else 'predicted'
        
        def convert_to_json_serializable(obj):
            if isinstance(obj, (np.integer, int)):
                return int(obj)
            elif isinstance(obj, (np.floating, float)):
                return float(obj)
            elif isinstance(obj, (np.bool_, bool)):
                return bool(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_to_json_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_json_serializable(item) for item in obj]
            else:
                return obj
        
        metrics = {
            'method': method,
            'total_questions': len(results_df),
            'avg_processing_time': np.mean(processing_times).item() if processing_times else 0.0,
            'total_processing_time': sum(processing_times)
        }
        
        has_real_answers = False
        if answer_column is not None and answer_column in results_df.columns:
            has_real_answers = results_df[answer_column].notna().any().item()
        
        if has_real_answers and 'is_correct' in results_df.columns:
            correct = results_df['is_correct'].sum().item()
            accuracy = (correct / len(results_df)).item() if len(results_df) > 0 else 0.0

            metrics.update({
                'correct_answers': correct,
                'accuracy': accuracy,
                'accuracy_percent': f"{accuracy * 100:.2f}%",
                'error_rate': (1 - accuracy).item()
            })

            category_metrics = {}
            for category, results in category_results.items():
                if results['truths']:
                    cat_total = len(results['truths'])
                    cat_correct = results['correct']
                    cat_accuracy = (cat_correct / cat_total) if cat_total > 0 else 0.0

                    category_metrics[category] = {
                        'total': cat_total,
                        'correct': cat_correct,
                        'accuracy': cat_accuracy,
                        'accuracy_percent': f"{cat_accuracy * 100:.2f}%"
                    }
                else:
                    category_metrics[category] = {
                        'total': results['total'],
                        'correct': 0,
                        'accuracy': 0.0,
                        'accuracy_percent': "0.00%",
                        'note': 'no ground truth answers'
                    }

            metrics['category_metrics'] = category_metrics
            
            max_classes = 10
            confusion = np.zeros((max_classes, max_classes), dtype=int)
            answer_count = 0
            
            for idx, row in results_df.iterrows():
                if pd.notna(row[answer_column]) and pd.notna(row[prediction_column]):
                    answer_count += 1
                    try:
                        true_val = self.parse_answer_index(str(row[answer_column]))
                    except:
                        true_val = 0
                    try:
                        pred_val = self.parse_answer_index(str(row[prediction_column]))
                    except:
                        pred_val = 0

                    if 0 <= true_val < max_classes and 0 <= pred_val < max_classes:
                        confusion[true_val][pred_val] += 1
            
            if answer_count > 0:
                metrics['confusion_matrix'] = confusion.tolist()

                per_class_accuracy = []
                for i in range(max_classes):
                    total_class = sum(confusion[i]).item()
                    if total_class > 0:
                        class_acc = (confusion[i][i] / total_class).item()
                        per_class_accuracy.append({
                            'class': i,
                            'correct': confusion[i][i].item(),
                            'total': total_class,
                            'accuracy': class_acc,
                            'accuracy_percent': f"{class_acc * 100:.2f}%"
                        })
                    else:
                        per_class_accuracy.append({
                            'class': i,
                            'correct': 0,
                            'total': 0,
                            'accuracy': 0.0,
                            'accuracy_percent': "0.00%",
                            'note': 'no instances'
                        })

                metrics['per_class_accuracy'] = per_class_accuracy
        else:
            metrics['note'] = 'no ground truth answers provided'
            category_metrics = {}
            for category, results in category_results.items():
                category_metrics[category] = {
                    'total': results['total'],
                    'predictions_made': len(results['predictions']),
                    'has_ground_truth': bool(len(results['truths']) > 0)
                }
            metrics['category_metrics'] = category_metrics
        
        return convert_to_json_serializable(metrics)

    def process_csv_files(
        self,
        questions_csv_path: str,
        answers_csv_path: Optional[str] = None,
        output_dir: str = "./results",
        output_filename: Optional[str] = None,
        method: Literal[
            "ensemble_vote",
            "generate_answer",
            "confidence_ensemble_vote",
            "generate_answer_selfcheck"
        ] = "ensemble_vote",
        save_intermediate: bool = True,
        **method_kwargs
    ) -> Tuple[pd.DataFrame, List[str]]:

        self._log("process_csv_files", "–Ω–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏", {
            "questions_file": questions_csv_path,
            "answers_file": answers_csv_path,
            "output_dir": output_dir,
            "method": method
        }, "DEBUG")

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {output_path.absolute()}")

        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        try:
            questions_df = pd.read_csv(questions_csv_path)
            unnamed_cols = [col for col in questions_df.columns if 'Unnamed' in str(col)]
            if unnamed_cols:
                questions_df = questions_df.rename(columns={unnamed_cols[0]: 'question_id'})
                print(f"  ‚úì –ë–µ–∑—ã–º—è–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∞ –≤ 'question_id'")

            required_cols = ['question', 'options', 'category']
            missing_cols = [col for col in required_cols if col not in questions_df.columns]

            if missing_cols:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")

            questions_df['question_id'] = questions_df['question_id'].astype(int)
            questions_df['question'] = questions_df['question'].astype(str)
            questions_df['options'] = questions_df['options'].astype(str)
            questions_df['category'] = questions_df['category'].astype(str)

            print(f"  ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(questions_df)} –≤–æ–ø—Ä–æ—Å–æ–≤")
            print(f"  ‚úì –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {questions_df['category'].unique()[:5]}")

        except Exception as e:
            self._log("process_csv_files", "–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–æ–ø—Ä–æ—Å–æ–≤", {"error": str(e)}, "DEBUG")
            raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏: {e}")

        answers_df = None
        answers_array = [] 

        if answers_csv_path:
            try:
                answers_df = pd.read_csv(answers_csv_path)
                unnamed_cols = [col for col in answers_df.columns if 'Unnamed' in str(col)]
                if unnamed_cols:
                    answers_df = answers_df.rename(columns={unnamed_cols[0]: 'question_id'})

                if 'answer' not in answers_df.columns:
                    other_cols = [col for col in answers_df.columns if col != 'question_id']
                    if len(other_cols) == 1:
                        answers_df = answers_df.rename(columns={other_cols[0]: 'true_answer'})
                    else:
                        raise ValueError("–ù–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É 'answer' –≤ —Ñ–∞–π–ª–µ —Å –æ—Ç–≤–µ—Ç–∞–º–∏")
                
                answers_df['question_id'] = answers_df['question_id'].astype(int)
                answers_df['true_answer'] = answers_df['true_answer'].astype(str)
                answers_array = answers_df['true_answer'].tolist()
                print(f"  ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(answers_df)} –æ—Ç–≤–µ—Ç–æ–≤")

                q_ids = set(questions_df['question_id'])
                a_ids = set(answers_df['question_id'])

                if q_ids != a_ids:
                    missing_in_answers = q_ids - a_ids
                    missing_in_questions = a_ids - q_ids

                    if missing_in_answers:
                        print(f"  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –û—Ç–≤–µ—Ç—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤: {sorted(missing_in_answers)[:10]}")
                    if missing_in_questions:
                        print(f"  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –õ–∏—à–Ω–∏–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤: {sorted(missing_in_questions)[:10]}")

            except Exception as e:
                self._log("process_csv_files", "–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤", {"error": str(e)}, "DEBUG")
                print(f"  ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Ç–≤–µ—Ç—ã: {e}")
                answers_df = None
                answers_array = []

        if answers_df is not None:
            merged_df = pd.merge(
                questions_df,
                answers_df[['question_id', 'true_answer']],
                on='question_id',
                how='left'
            )
            merged_df['has_answer'] = merged_df['true_answer'].notna()
            print(f"  ‚úì –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {merged_df['has_answer'].sum()} –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –æ—Ç–≤–µ—Ç–∞–º–∏, "
                f"{len(merged_df) - merged_df['has_answer'].sum()} –±–µ–∑ –æ—Ç–≤–µ—Ç–æ–≤")
        else:
            merged_df = questions_df.copy()
            merged_df['true_answer'] = None
            merged_df['has_answer'] = False
            print("  ‚úì –û—Ç–≤–µ—Ç—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã, –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

        print(f"\nü§ñ –ó–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏ (–º–µ—Ç–æ–¥: {method})...")
        
        answer_column = "true_answer" if 'true_answer' in merged_df.columns else None
        eval_kwargs = {
            "question_column": "question",
            "options_column": "options",
            "category_column": "category",
            "answer_column": answer_column,
            "method": method,
            "method_kwargs": method_kwargs
        }

        eval_kwargs = {k: v for k, v in eval_kwargs.items() if v is not None}

        if save_intermediate:
            intermediate_path = output_path / "intermediate_data.csv"
            merged_df.to_csv(intermediate_path, index=False)
            print(f"  üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {intermediate_path}")

        try:
            results_df, metrics = self.evaluate_dataframe(
                merged_df,
                **eval_kwargs
            )

            print("\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(results_df)}")
            
            if answer_column and merged_df[answer_column].notna().any():
                if 'is_correct' in results_df.columns:
                    correct = results_df['is_correct'].sum()
                    accuracy = correct / len(results_df) if len(results_df) > 0 else 0
                    print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {correct}/{len(results_df)} ({accuracy:.2%})")
                else:
                    print("‚ÑπÔ∏è  –ö–æ–ª–æ–Ω–∫–∞ 'is_correct' –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
            else:
                print("‚ÑπÔ∏è  –û—Ç–≤–µ—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã, —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–µ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è")
        
        except Exception as e:
            self._log("process_csv_files", "–æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ", {"error": str(e)}, "DEBUG")
            if save_intermediate and intermediate_path.exists():
                print("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏...")
                results_df = pd.read_csv(intermediate_path)
                results_df['predicted'] = 0
                results_df['is_correct'] = False
                metrics = {'error': str(e)}
            else:
                raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")

        print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        if output_filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            model_name_safe = self.model_name.replace("/", "_")
            output_filename = f"results_{model_name_safe}_{timestamp}.csv"

        output_filepath = output_path / output_filename
        
        results_df = results_df.rename(columns={'predicted': 'answer'})
        
        final_columns = [
            'question_id', 'question', 'category',
            'answer',
            'processing_time'
        ]
        
        if 'true_answer' in results_df.columns and results_df['true_answer'].notna().any():
            final_columns.append('true_answer')
        
        if 'options' in results_df.columns:
            results_df['options_preview'] = results_df['options'].apply(
                lambda x: str(x)[:200] + "..." if len(str(x)) > 200 else str(x)
            )
            final_columns.append('options_preview')
        
        if 'is_correct' in results_df.columns and results_df['is_correct'].notna().any():
            final_columns.append('is_correct')
        
        final_df = results_df[final_columns].copy()

        try:
            final_df.to_csv(output_filepath, index=False, encoding='utf-8-sig')
            import os
            if os.path.exists(output_filepath):
                file_size = os.path.getsize(output_filepath)
                print(f"  ‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {output_filepath}")
                print(f"  üìÑ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size / 1024:.1f} KB ({file_size} –±–∞–π—Ç)")
                try:
                    preview_df = pd.read_csv(output_filepath, nrows=3)
                    print("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä (–ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏):")
                    print(preview_df.to_string(index=False))
                except Exception as e:
                    print(f"  üëÄ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω, –Ω–æ –Ω–µ —á–∏—Ç–∞–µ—Ç—Å—è –∫–∞–∫ CSV: {e}")
            else:
                print(f"  ‚ùó –§–ê–ô–õ –ù–ï –°–û–ó–î–ê–ù! –ü—Ä–æ–≤–µ—Ä—å –ø—É—Ç—å: {output_filepath}")
                
        except Exception as e:
            print(f"  ‚ùó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            print("  ‚ùó –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π –ø—É—Ç—å –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞")

        if not answers_array:
            print("  ‚ÑπÔ∏è  –ú–∞—Å—Å–∏–≤ –æ—Ç–≤–µ—Ç–æ–≤ –ø—É—Å—Ç–æ–π (—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –∏–ª–∏ –ø—É—Å—Ç)")

        if metrics and self.DEBUG:
            print("\nüìä –ú–ï–¢–†–ò–ö–ò:")
            print("-" * 40)
            for key, value in metrics.items():
                if key not in ['confusion_matrix', 'per_class_accuracy', 'category_metrics']:
                    print(f"  {key}: {value}")
            print("-" * 40)


        print(f"\n{'='*60}")
        print("–°–í–û–î–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
        print(f"{'='*60}")
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(final_df)}")
        print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(sorted(final_df['category'].unique()))}")

        print(f"\nüìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–ê–°–°–ò–í–ï –û–¢–í–ï–¢–û–í:")
        print(f"  –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤ –≤ –º–∞—Å—Å–∏–≤–µ: {len(answers_array)}")
        if answers_array:
            null_count = sum(1 for a in answers_array if pd.isna(a) or str(a).strip() == '' or str(a).lower() == 'none')
            print(f"  –ü—É—Å—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {null_count}")
            unique_answers = len(set(str(a) for a in answers_array if pd.notna(a)))
            print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {unique_answers}")
            
            print(f"\nüìñ –ü–µ—Ä–≤—ã–µ 10 –æ—Ç–≤–µ—Ç–æ–≤:")
            print("-" * 40)
            for i, answer in enumerate(answers_array[:10]):
                answer_str = str(answer) if pd.notna(answer) else "[–ø—É—Å—Ç–æ]"
                print(f"{i+1:3d}. {answer_str[:100]}{'...' if len(answer_str) > 100 else ''}")
            print("-" * 40)
        else:
            print("  ‚ÑπÔ∏è  –ú–∞—Å—Å–∏–≤ –æ—Ç–≤–µ—Ç–æ–≤ –ø—É—Å—Ç–æ–π (—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω)")

        if 'is_correct' in final_df.columns and final_df['is_correct'].notna().any():
            accuracy = final_df['is_correct'].mean()
            print(f"\nüéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
            if len(final_df['category'].unique()) > 1:
                print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                for category in sorted(final_df['category'].unique()):
                    cat_df = final_df[final_df['category'] == category]
                    if len(cat_df) > 0 and 'is_correct' in cat_df.columns:
                        cat_acc = cat_df['is_correct'].mean()
                        print(f"  {category}: {cat_acc:.2%} ({len(cat_df)} –≤–æ–ø—Ä–æ—Å–æ–≤)")
        else:
            print("\n‚ÑπÔ∏è  –¢–æ—á–Ω–æ—Å—Ç—å –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞ (–Ω–µ—Ç –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)")

        avg_time = final_df['processing_time'].mean() if 'processing_time' in final_df.columns else 0
        print(f"\n‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –≤–æ–ø—Ä–æ—Å: {avg_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üíæ –§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {output_filepath}")
        print(f"{'='*60}")

        self._log("process_csv_files", "–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞", {
            "output_file": str(output_filepath),
            "rows_processed": len(final_df),
            "answers_count": len(answers_array),
            "has_answers": answers_csv_path is not None
        }, "DEBUG")

        return final_df, answers_array


exp = LLM(
    model=model_14b,
    tokenizer=tokenizer_14b,
    deep_debug=True,
    use_llm_parsing=True,
    use_selfcheck=False,
    llm_few_shot_generation=False,
    llm_cot_generation=True,
)


exp.process_csv_files(
    questions_csv_path="/kaggle/input/LR1_dev.csv",
    answers_csv_path="/kaggle/input/LR1_dev_answers.csv",
    output_dir="/kaggle/working",
    method="generate_answer"
)

